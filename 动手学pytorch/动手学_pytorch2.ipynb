{"cells":[{"metadata":{"id":"F68298420C154AE5A017CF5BDF69310C","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"## æ¨¡å‹é€‰æ‹©ã€è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆ\n- **æ¨¡å‹é€‰æ‹©**\n\t1.**éªŒè¯æ•°æ®é›†**\n\tä»ä¸¥æ ¼æ„ä¹‰ä¸Šè®²ï¼Œæµ‹è¯•é›†åªèƒ½åœ¨æ‰€æœ‰è¶…å‚æ•°å’Œæ¨¡å‹å‚æ•°é€‰å®šåä½¿ç”¨ä¸€æ¬¡ã€‚ä¸å¯ä»¥ä½¿ç”¨æµ‹è¯•æ•°æ®é€‰æ‹©æ¨¡å‹ï¼Œå¦‚è°ƒå‚ã€‚ç”±äºæ— æ³•ä»è®­ç»ƒè¯¯å·®ä¼°è®¡æ³›åŒ–è¯¯å·®ï¼Œå› æ­¤ä¹Ÿä¸åº”åªä¾èµ–è®­ç»ƒæ•°æ®é€‰æ‹©æ¨¡å‹ã€‚é‰´äºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥é¢„ç•™ä¸€éƒ¨åˆ†åœ¨è®­ç»ƒæ•°æ®é›†å’Œæµ‹è¯•æ•°æ®é›†ä»¥å¤–çš„æ•°æ®æ¥è¿›è¡Œæ¨¡å‹é€‰æ‹©ã€‚è¿™éƒ¨åˆ†æ•°æ®è¢«ç§°ä¸ºéªŒè¯æ•°æ®é›†ï¼Œç®€ç§°éªŒè¯é›†ï¼ˆvalidation setï¼‰ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä»ç»™å®šçš„è®­ç»ƒé›†ä¸­éšæœºé€‰å–ä¸€å°éƒ¨åˆ†ä½œä¸ºéªŒè¯é›†ï¼Œè€Œå°†å‰©ä½™éƒ¨åˆ†ä½œä¸ºçœŸæ­£çš„è®­ç»ƒé›†ã€‚\n\t2.**KæŠ˜äº¤å‰éªŒè¯**   \n\tç”±äºéªŒè¯æ•°æ®é›†ä¸å‚ä¸æ¨¡å‹è®­ç»ƒï¼Œå½“è®­ç»ƒæ•°æ®ä¸å¤Ÿç”¨æ—¶ï¼Œé¢„ç•™å¤§é‡çš„éªŒè¯æ•°æ®æ˜¾å¾—å¤ªå¥¢ä¾ˆã€‚ä¸€ç§æ”¹å–„çš„æ–¹æ³•æ˜¯KæŠ˜äº¤å‰éªŒè¯ï¼ˆK-fold cross-validationï¼‰ã€‚åœ¨KæŠ˜äº¤å‰éªŒè¯ä¸­ï¼Œæˆ‘ä»¬æŠŠåŸå§‹è®­ç»ƒæ•°æ®é›†åˆ†å‰²æˆKä¸ªä¸é‡åˆçš„å­æ•°æ®é›†ï¼Œç„¶åæˆ‘ä»¬åšKæ¬¡æ¨¡å‹è®­ç»ƒå’ŒéªŒè¯ã€‚æ¯ä¸€æ¬¡ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªå­æ•°æ®é›†éªŒè¯æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨å…¶ä»–K-1ä¸ªå­æ•°æ®é›†æ¥è®­ç»ƒæ¨¡å‹ã€‚åœ¨è¿™Kæ¬¡è®­ç»ƒå’ŒéªŒè¯ä¸­ï¼Œæ¯æ¬¡ç”¨æ¥éªŒè¯æ¨¡å‹çš„å­æ•°æ®é›†éƒ½ä¸åŒã€‚æœ€åï¼Œæˆ‘ä»¬å¯¹è¿™Kæ¬¡è®­ç»ƒè¯¯å·®å’ŒéªŒè¯è¯¯å·®åˆ†åˆ«æ±‚å¹³å‡ã€‚\n\t\n\n- **è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆ** \n\tæ¨¡å‹è®­ç»ƒä¸­ç»å¸¸å‡ºç°çš„ä¸¤ç±»å…¸å‹é—®é¢˜ï¼š\nä¸€ç±»æ˜¯æ¨¡å‹æ— æ³•å¾—åˆ°è¾ƒä½çš„è®­ç»ƒè¯¯å·®ï¼Œæˆ‘ä»¬å°†è¿™ä¸€ç°è±¡ç§°ä½œæ¬ æ‹Ÿåˆï¼ˆunderfittingï¼‰ï¼›\nå¦ä¸€ç±»æ˜¯æ¨¡å‹çš„è®­ç»ƒè¯¯å·®è¿œå°äºå®ƒåœ¨æµ‹è¯•æ•°æ®é›†ä¸Šçš„è¯¯å·®ï¼Œæˆ‘ä»¬ç§°è¯¥ç°è±¡ä¸ºè¿‡æ‹Ÿåˆï¼ˆoverfittingï¼‰ã€‚\nåœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬è¦å°½å¯èƒ½åŒæ—¶åº”å¯¹æ¬ æ‹Ÿåˆå’Œè¿‡æ‹Ÿåˆã€‚\n\t1.**æ¨¡å‹å¤æ‚åº¦**\n\tç»™å®šä¸€ä¸ªç”±æ ‡é‡æ•°æ®ç‰¹å¾$x$å’Œå¯¹åº”çš„æ ‡é‡æ ‡ç­¾$y$ç»„æˆçš„è®­ç»ƒæ•°æ®é›†ï¼Œå¤šé¡¹å¼å‡½æ•°æ‹Ÿåˆçš„ç›®æ ‡æ˜¯æ‰¾ä¸€ä¸ª$K$é˜¶å¤šé¡¹å¼å‡½æ•°\n$$\n \\hat{y} = b + \\sum_{k=1}^K x^k w_k \n$$\næ¥è¿‘ä¼¼ $y$ã€‚åœ¨ä¸Šå¼ä¸­ï¼Œ$w_k$æ˜¯æ¨¡å‹çš„æƒé‡å‚æ•°ï¼Œ$b$æ˜¯åå·®å‚æ•°ã€‚ä¸çº¿æ€§å›å½’ç›¸åŒï¼Œå¤šé¡¹å¼å‡½æ•°æ‹Ÿåˆä¹Ÿä½¿ç”¨å¹³æ–¹æŸå¤±å‡½æ•°ã€‚ç‰¹åˆ«åœ°ï¼Œä¸€é˜¶å¤šé¡¹å¼å‡½æ•°æ‹Ÿåˆåˆå«çº¿æ€§å‡½æ•°æ‹Ÿåˆã€‚\nç»™å®šè®­ç»ƒæ•°æ®é›†ï¼Œæ¨¡å‹å¤æ‚åº¦å’Œè¯¯å·®ä¹‹é—´çš„å…³ç³»ï¼š\n![Image Name](https://cdn.kesci.com/upload/image/q5jc27wxoj.png?imageView2/0/w/960/h/960)\n\t2.**è®­ç»ƒæ•°æ®é›†å¤§å°**\n\tå½±å“æ¬ æ‹Ÿåˆå’Œè¿‡æ‹Ÿåˆçš„å¦ä¸€ä¸ªé‡è¦å› ç´ æ˜¯è®­ç»ƒæ•°æ®é›†çš„å¤§å°ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œå¦‚æœè®­ç»ƒæ•°æ®é›†ä¸­æ ·æœ¬æ•°è¿‡å°‘ï¼Œç‰¹åˆ«æ˜¯æ¯”æ¨¡å‹å‚æ•°æ•°é‡ï¼ˆæŒ‰å…ƒç´ è®¡ï¼‰æ›´å°‘æ—¶ï¼Œè¿‡æ‹Ÿåˆæ›´å®¹æ˜“å‘ç”Ÿã€‚æ­¤å¤–ï¼Œæ³›åŒ–è¯¯å·®ä¸ä¼šéšè®­ç»ƒæ•°æ®é›†é‡Œæ ·æœ¬æ•°é‡å¢åŠ è€Œå¢å¤§ã€‚å› æ­¤ï¼Œåœ¨è®¡ç®—èµ„æºå…è®¸çš„èŒƒå›´ä¹‹å†…ï¼Œæˆ‘ä»¬é€šå¸¸å¸Œæœ›è®­ç»ƒæ•°æ®é›†å¤§ä¸€äº›ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¨¡å‹å¤æ‚åº¦è¾ƒé«˜æ—¶ï¼Œä¾‹å¦‚å±‚æ•°è¾ƒå¤šçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚\n\t\n- **è§£å†³æ–¹æ³•**\n\t1.**æ­£åˆ™åŒ–**\n\té€šè¿‡ä¸ºæ¨¡å‹æŸå¤±å‡½æ•°æ·»åŠ æƒ©ç½šé¡¹ä½¿å­¦å‡ºçš„æ¨¡å‹å‚æ•°å€¼è¾ƒå°ï¼Œæ˜¯åº”å¯¹è¿‡æ‹Ÿåˆçš„å¸¸ç”¨æ‰‹æ®µã€‚\n\t$L_2$èŒƒæ•°æ­£åˆ™åŒ–ä»¤**æƒé‡$w_1$å’Œ$w_2$å…ˆè‡ªä¹˜å°äº1çš„æ•°ï¼Œå†å‡å»ä¸å«æƒ©ç½šé¡¹çš„æ¢¯åº¦**ã€‚å› æ­¤ï¼Œ$L_2$èŒƒæ•°æ­£åˆ™åŒ–åˆå«**æƒé‡è¡°å‡**ã€‚æƒé‡è¡°å‡é€šè¿‡æƒ©ç½šç»å¯¹å€¼è¾ƒå¤§çš„æ¨¡å‹å‚æ•°ä¸ºéœ€è¦å­¦ä¹ çš„æ¨¡å‹å¢åŠ äº†é™åˆ¶ï¼Œè¿™å¯èƒ½å¯¹è¿‡æ‹Ÿåˆæœ‰æ•ˆã€‚\n\t2.**ä¸¢å¼ƒæ³•**\n\tå¤šå±‚æ„ŸçŸ¥æœºä¸­ç¥ç»ç½‘ç»œå›¾æè¿°äº†ä¸€ä¸ªå•éšè—å±‚çš„å¤šå±‚æ„ŸçŸ¥æœºã€‚å…¶ä¸­è¾“å…¥ä¸ªæ•°ä¸º4ï¼Œéšè—å•å…ƒä¸ªæ•°ä¸º5ï¼Œä¸”éšè—å•å…ƒ$h_i$ï¼ˆ$i=1, \\ldots, 5$ï¼‰çš„è®¡ç®—è¡¨è¾¾å¼ä¸º\n$$\n h_i = \\phi\\left(x_1 w_{1i} + x_2 w_{2i} + x_3 w_{3i} + x_4 w_{4i} + b_i\\right) \n$$\nè¿™é‡Œ$\\phi$æ˜¯æ¿€æ´»å‡½æ•°ï¼Œ$x_1, \\ldots, x_4$æ˜¯è¾“å…¥ï¼Œéšè—å•å…ƒ$i$çš„æƒé‡å‚æ•°ä¸º$w_{1i}, \\ldots, w_{4i}$ï¼Œåå·®å‚æ•°ä¸º$b_i$ã€‚å½“å¯¹è¯¥éšè—å±‚ä½¿ç”¨ä¸¢å¼ƒæ³•æ—¶ï¼Œè¯¥å±‚çš„éšè—å•å…ƒå°†æœ‰ä¸€å®šæ¦‚ç‡è¢«ä¸¢å¼ƒæ‰ã€‚è®¾ä¸¢å¼ƒæ¦‚ç‡ä¸º$p$ï¼Œé‚£ä¹ˆæœ‰$p$çš„æ¦‚ç‡$h_i$ä¼šè¢«æ¸…é›¶ï¼Œæœ‰$1-p$çš„æ¦‚ç‡$h_i$ä¼šé™¤ä»¥$1-p$åšæ‹‰ä¼¸ã€‚ä¸¢å¼ƒæ¦‚ç‡æ˜¯ä¸¢å¼ƒæ³•çš„è¶…å‚æ•°ã€‚å…·ä½“æ¥è¯´ï¼Œè®¾éšæœºå˜é‡$\\xi_i$ä¸º0å’Œ1çš„æ¦‚ç‡åˆ†åˆ«ä¸º$p$å’Œ$1-p$ã€‚ä½¿ç”¨ä¸¢å¼ƒæ³•æ—¶æˆ‘ä»¬è®¡ç®—æ–°çš„éšè—å•å…ƒ$h_i'$\n$$\n h_i' = \\frac{\\xi_i}{1-p} h_i \n$$\nç”±äº$E(\\xi_i) = 1-p$ï¼Œå› æ­¤\n$$\n E(h_i') = \\frac{E(\\xi_i)}{1-p}h_i = h_i \n$$\nå³ä¸¢å¼ƒæ³•ä¸æ”¹å˜å…¶è¾“å…¥çš„æœŸæœ›å€¼ã€‚è®©æˆ‘ä»¬å¯¹ä¹‹å‰å¤šå±‚æ„ŸçŸ¥æœºçš„ç¥ç»ç½‘ç»œä¸­çš„éšè—å±‚ä½¿ç”¨ä¸¢å¼ƒæ³•ï¼Œä¸€ç§å¯èƒ½çš„ç»“æœå¦‚å›¾æ‰€ç¤ºï¼Œå…¶ä¸­$h_2$å’Œ$h_5$è¢«æ¸…é›¶ã€‚è¿™æ—¶è¾“å‡ºå€¼çš„è®¡ç®—ä¸å†ä¾èµ–$h_2$å’Œ$h_5$ï¼Œåœ¨åå‘ä¼ æ’­æ—¶ï¼Œä¸è¿™ä¸¤ä¸ªéšè—å•å…ƒç›¸å…³çš„æƒé‡çš„æ¢¯åº¦å‡ä¸º0ã€‚ç”±äºåœ¨è®­ç»ƒä¸­éšè—å±‚ç¥ç»å…ƒçš„ä¸¢å¼ƒæ˜¯éšæœºçš„ï¼Œå³$h_1, \\ldots, h_5$éƒ½æœ‰å¯èƒ½è¢«æ¸…é›¶ï¼Œè¾“å‡ºå±‚çš„è®¡ç®—æ— æ³•è¿‡åº¦ä¾èµ–$h_1, \\ldots, h_5$ä¸­çš„ä»»ä¸€ä¸ªï¼Œä»è€Œåœ¨è®­ç»ƒæ¨¡å‹æ—¶èµ·åˆ°æ­£åˆ™åŒ–çš„ä½œç”¨ï¼Œå¹¶å¯ä»¥ç”¨æ¥åº”å¯¹è¿‡æ‹Ÿåˆã€‚åœ¨æµ‹è¯•æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬ä¸ºäº†æ‹¿åˆ°æ›´åŠ ç¡®å®šæ€§çš„ç»“æœï¼Œä¸€èˆ¬ä¸ä½¿ç”¨ä¸¢å¼ƒæ³•\n![Image Name](https://cdn.kesci.com/upload/image/q5jd69in3m.png?imageView2/0/w/960/h/960)"},{"metadata":{"id":"CD1A38B37FB2489C9B5E7C5240A11AEB","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def dropout(X, drop_prob):\n    X = X.float()\n    assert 0 <= drop_prob <= 1\n    keep_prob = 1 - drop_prob\n    # è¿™ç§æƒ…å†µä¸‹æŠŠå…¨éƒ¨å…ƒç´ éƒ½ä¸¢å¼ƒ\n    if keep_prob == 0:\n        return torch.zeros_like(X)\n    mask = (torch.rand(X.shape) < keep_prob).float()\n    \n    return mask * X / keep_prob\n    \ndrop_prob1, drop_prob2 = 0.2, 0.5\ndef net(X, is_training=True):\n    X = X.view(-1, num_inputs)\n    H1 = (torch.matmul(X, W1) + b1).relu()\n    if is_training:  # åªåœ¨è®­ç»ƒæ¨¡å‹æ—¶ä½¿ç”¨ä¸¢å¼ƒæ³•\n        H1 = dropout(H1, drop_prob1)  # åœ¨ç¬¬ä¸€å±‚å…¨è¿æ¥åæ·»åŠ ä¸¢å¼ƒå±‚\n    H2 = (torch.matmul(H1, W2) + b2).relu()\n    if is_training:\n        H2 = dropout(H2, drop_prob2)  # åœ¨ç¬¬äºŒå±‚å…¨è¿æ¥åæ·»åŠ ä¸¢å¼ƒå±‚\n    return torch.matmul(H2, W3) + b3","execution_count":1},{"metadata":{"cell_type":"code","id":"509C94777E2E416D86BC6AD4DAEE8DBA","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"## æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸\næ·±åº¦æ¨¡å‹æœ‰å…³æ•°å€¼ç¨³å®šæ€§çš„å…¸å‹é—®é¢˜æ˜¯æ¶ˆå¤±ï¼ˆvanishingï¼‰å’Œçˆ†ç‚¸ï¼ˆexplosionï¼‰ã€‚\n- **å½“ç¥ç»ç½‘ç»œçš„å±‚æ•°è¾ƒå¤šæ—¶ï¼Œæ¨¡å‹çš„æ•°å€¼ç¨³å®šæ€§å®¹æ˜“å˜å·®ã€‚**\n\tå‡è®¾ä¸€ä¸ªå±‚æ•°ä¸º$L$çš„å¤šå±‚æ„ŸçŸ¥æœºçš„ç¬¬$l$å±‚$\\boldsymbol{H}^{(l)}$çš„æƒé‡å‚æ•°ä¸º$\\boldsymbol{W}^{(l)}$ï¼Œè¾“å‡ºå±‚$\\boldsymbol{H}^{(L)}$çš„æƒé‡å‚æ•°ä¸º$\\boldsymbol{W}^{(L)}$ã€‚ä¸ºäº†ä¾¿äºè®¨è®ºï¼Œä¸è€ƒè™‘åå·®å‚æ•°ï¼Œä¸”è®¾æ‰€æœ‰éšè—å±‚çš„æ¿€æ´»å‡½æ•°ä¸ºæ’ç­‰æ˜ å°„ï¼ˆidentity mappingï¼‰$\\phi(x) = x$ã€‚ç»™å®šè¾“å…¥$\\boldsymbol{X}$ï¼Œå¤šå±‚æ„ŸçŸ¥æœºçš„ç¬¬$l$å±‚çš„è¾“å‡º$\\boldsymbol{H}^{(l)} = \\boldsymbol{X} \\boldsymbol{W}^{(1)} \\boldsymbol{W}^{(2)} \\ldots \\boldsymbol{W}^{(l)}$ã€‚æ­¤æ—¶ï¼Œå¦‚æœå±‚æ•°$l$è¾ƒå¤§ï¼Œ$\\boldsymbol{H}^{(l)}$çš„è®¡ç®—å¯èƒ½ä¼šå‡ºç°è¡°å‡æˆ–çˆ†ç‚¸ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œå‡è®¾è¾“å…¥å’Œæ‰€æœ‰å±‚çš„æƒé‡å‚æ•°éƒ½æ˜¯æ ‡é‡ï¼Œå¦‚æƒé‡å‚æ•°ä¸º0.2å’Œ5ï¼Œå¤šå±‚æ„ŸçŸ¥æœºçš„ç¬¬30å±‚è¾“å‡ºä¸ºè¾“å…¥$\\boldsymbol{X}$åˆ†åˆ«ä¸$0.2^{30} \\approx 1 \\times 10^{-21}$ï¼ˆæ¶ˆå¤±ï¼‰å’Œ$5^{30} \\approx 9 \\times 10^{20}$ï¼ˆçˆ†ç‚¸ï¼‰çš„ä¹˜ç§¯ã€‚å½“å±‚æ•°è¾ƒå¤šæ—¶ï¼Œæ¢¯åº¦çš„è®¡ç®—ä¹Ÿå®¹æ˜“å‡ºç°æ¶ˆå¤±æˆ–çˆ†ç‚¸ã€‚\n\t\n- **éšæœºåˆå§‹åŒ–æ¨¡å‹å‚æ•°çš„åŸå› **\n\tå‡è®¾è¾“å‡ºå±‚åªä¿ç•™ä¸€ä¸ªè¾“å‡ºå•å…ƒ$o_1$ï¼ˆåˆ å»$o_2$å’Œ$o_3$ä»¥åŠæŒ‡å‘å®ƒä»¬çš„ç®­å¤´ï¼‰ï¼Œä¸”éšè—å±‚ä½¿ç”¨ç›¸åŒçš„æ¿€æ´»å‡½æ•°ã€‚å¦‚æœå°†æ¯ä¸ªéšè—å•å…ƒçš„å‚æ•°éƒ½åˆå§‹åŒ–ä¸ºç›¸ç­‰çš„å€¼ï¼Œé‚£ä¹ˆåœ¨æ­£å‘ä¼ æ’­æ—¶æ¯ä¸ªéšè—å•å…ƒå°†æ ¹æ®ç›¸åŒçš„è¾“å…¥è®¡ç®—å‡ºç›¸åŒçš„å€¼ï¼Œå¹¶ä¼ é€’è‡³è¾“å‡ºå±‚ã€‚åœ¨åå‘ä¼ æ’­ä¸­ï¼Œæ¯ä¸ªéšè—å•å…ƒçš„å‚æ•°æ¢¯åº¦å€¼ç›¸ç­‰ã€‚å› æ­¤ï¼Œè¿™äº›å‚æ•°åœ¨ä½¿ç”¨åŸºäºæ¢¯åº¦çš„ä¼˜åŒ–ç®—æ³•è¿­ä»£åå€¼ä¾ç„¶ç›¸ç­‰ã€‚ä¹‹åçš„è¿­ä»£ä¹Ÿæ˜¯å¦‚æ­¤ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ— è®ºéšè—å•å…ƒæœ‰å¤šå°‘ï¼Œéšè—å±‚æœ¬è´¨ä¸Šåªæœ‰1ä¸ªéšè—å•å…ƒåœ¨å‘æŒ¥ä½œç”¨ã€‚å› æ­¤ï¼Œæ­£å¦‚åœ¨å‰é¢çš„å®éªŒä¸­æ‰€åšçš„é‚£æ ·ï¼Œæˆ‘ä»¬é€šå¸¸å°†ç¥ç»ç½‘ç»œçš„æ¨¡å‹å‚æ•°ï¼Œç‰¹åˆ«æ˜¯æƒé‡å‚æ•°ï¼Œè¿›è¡Œéšæœºåˆå§‹åŒ–ã€‚\n\t1. PyTorchçš„é»˜è®¤éšæœºåˆå§‹åŒ– \n\t åœ¨çº¿æ€§å›å½’çš„ç®€æ´å®ç°ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨`torch.nn.init.normal_()`ä½¿æ¨¡å‹`net`çš„æƒé‡å‚æ•°é‡‡ç”¨æ­£æ€åˆ†å¸ƒçš„éšæœºåˆå§‹åŒ–æ–¹å¼ã€‚ä¸è¿‡ï¼ŒPyTorchä¸­`nn.Module`çš„æ¨¡å—å‚æ•°éƒ½é‡‡å–äº†è¾ƒä¸ºåˆç†çš„åˆå§‹åŒ–ç­–ç•¥ï¼ˆä¸åŒç±»å‹çš„layerå…·ä½“é‡‡æ ·çš„å“ªä¸€ç§åˆå§‹åŒ–æ–¹æ³•çš„å¯å‚è€ƒ[æºä»£ç ](https://github.com/pytorch/pytorch/tree/master/torch/nn/modules)ï¼‰ï¼Œå› æ­¤ä¸€èˆ¬ä¸ç”¨æˆ‘ä»¬è€ƒè™‘\n\t2. Xavieréšæœºåˆå§‹åŒ–\n\tå‡è®¾æŸå…¨è¿æ¥å±‚çš„è¾“å…¥ä¸ªæ•°ä¸º$a$ï¼Œè¾“å‡ºä¸ªæ•°ä¸º$b$ï¼ŒXavieréšæœºåˆå§‹åŒ–å°†ä½¿è¯¥å±‚ä¸­æƒé‡å‚æ•°çš„æ¯ä¸ªå…ƒç´ éƒ½éšæœºé‡‡æ ·äºå‡åŒ€åˆ†å¸ƒ\n$$\nU\\left(-\\sqrt{\\frac{6}{a+b}}, \\sqrt{\\frac{6}{a+b}}\\right).\n$$\nå®ƒçš„è®¾è®¡ä¸»è¦è€ƒè™‘åˆ°ï¼Œæ¨¡å‹å‚æ•°åˆå§‹åŒ–åï¼Œæ¯å±‚è¾“å‡ºçš„æ–¹å·®ä¸è¯¥å—è¯¥å±‚è¾“å…¥ä¸ªæ•°å½±å“ï¼Œä¸”æ¯å±‚æ¢¯åº¦çš„æ–¹å·®ä¹Ÿä¸è¯¥å—è¯¥å±‚è¾“å‡ºä¸ªæ•°å½±å“ã€‚"},{"metadata":{"id":"A3C74B45AD414C969E95EB6A345A2EB0","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"## å¾ªç¯ç¥ç»ç½‘ç»œè¿›é˜¶\n\n### GRU\nRNNå­˜åœ¨çš„é—®é¢˜ï¼šæ¢¯åº¦è¾ƒå®¹æ˜“å‡ºç°è¡°å‡æˆ–çˆ†ç‚¸ï¼ˆBPTTï¼‰  \nGRUâ»”æ§å¾ªç¯ç¥ç»â½¹ç»œï¼šæ•æ‰æ—¶é—´åºåˆ—ä¸­æ—¶é—´æ­¥è·ç¦»è¾ƒâ¼¤çš„ä¾èµ–å…³ç³» ,è§£å†³é•¿æœŸè®°å¿†å’Œåå‘ä¼ æ’­ä¸­çš„æ¢¯åº¦ç­‰é—®é¢˜ã€‚\nâ€¢ é‡ç½®â»”æœ‰åŠ©äºæ•æ‰æ—¶é—´åºåˆ—â¾¥çŸ­æœŸçš„ä¾èµ–å…³ç³»ï¼›  \nâ€¢ æ›´æ–°â»”æœ‰åŠ©äºæ•æ‰æ—¶é—´åºåˆ—â¾¥â»“æœŸçš„ä¾èµ–å…³ç³»ã€‚ \n\n- **GRUçš„è¾“å…¥è¾“å‡ºç»“æ„**\nGRUçš„è¾“å…¥è¾“å‡ºç»“æ„ä¸æ™®é€šçš„RNNæ˜¯ä¸€æ ·çš„ã€‚\næœ‰ä¸€ä¸ªå½“å‰çš„è¾“å…¥$x^t$ ï¼Œå’Œä¸Šä¸€ä¸ªèŠ‚ç‚¹ä¼ é€’ä¸‹æ¥çš„éšçŠ¶æ€ï¼ˆhidden stateï¼‰$h^{t-1}$ï¼Œè¿™ä¸ªéšçŠ¶æ€åŒ…å«äº†ä¹‹å‰èŠ‚ç‚¹çš„ç›¸å…³ä¿¡æ¯ã€‚\nç»“åˆ$x^t$ å’Œ$h^{t-1}$ï¼ŒGRUä¼šå¾—åˆ°å½“å‰éšè—èŠ‚ç‚¹çš„è¾“å‡º$y^t$ å’Œä¼ é€’ç»™ä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„éšçŠ¶æ€$h^t$ã€‚\n![Image Name](https://cdn.kesci.com/upload/image/q5srwnnmv7.png?imageView2/0/w/360/h/360)\n\n- **GRUçš„å†…éƒ¨ç»“æ„**\né¦–å…ˆï¼Œæˆ‘ä»¬å…ˆé€šè¿‡ä¸Šä¸€ä¸ªä¼ è¾“ä¸‹æ¥çš„çŠ¶æ€ $h^{t-1}$ å’Œå½“å‰èŠ‚ç‚¹çš„è¾“å…¥$x^t$ æ¥è·å–ä¸¤ä¸ªé—¨æ§çŠ¶æ€ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå…¶ä¸­$r$æ§åˆ¶é‡ç½®çš„é—¨æ§ï¼ˆreset gateï¼‰ï¼Œ$z$ä¸ºæ§åˆ¶æ›´æ–°çš„é—¨æ§ï¼ˆupdate gateï¼‰ã€‚\n![Image Name](https://cdn.kesci.com/upload/image/q5ss7lod3r.png?imageView2/0/w/360/h/360)\n\nå¾—åˆ°é—¨æ§ä¿¡å·ä¹‹åï¼Œé¦–å…ˆä½¿ç”¨é‡ç½®é—¨æ§æ¥å¾—åˆ°â€œé‡ç½®â€ä¹‹åçš„æ•°æ®$h^{t-1'}=h^{t-1}âŠ™r$ ï¼Œå†å°†$h^{t-1'}$ä¸è¾“å…¥ $x^r$ è¿›è¡Œæ‹¼æ¥ï¼Œå†é€šè¿‡ä¸€ä¸ªtanhæ¿€æ´»å‡½æ•°æ¥å°†æ•°æ®æ”¾ç¼©åˆ°-1~1çš„èŒƒå›´å†…ã€‚å³å¾—åˆ°å¦‚ä¸‹å›¾æ‰€ç¤ºçš„$h'$ ã€‚\n![Image Name](https://cdn.kesci.com/upload/image/q5ssjfuxhf.png?imageView2/0/w/960/h/960)\n\nè¿™é‡Œçš„$h'$ä¸»è¦æ˜¯åŒ…å«äº†å½“å‰è¾“å…¥çš„$x^t$æ•°æ®ã€‚æœ‰é’ˆå¯¹æ€§åœ°å¯¹$h'$æ·»åŠ åˆ°å½“å‰çš„éšè—çŠ¶æ€ï¼Œç›¸å½“äºâ€è®°å¿†äº†å½“å‰æ—¶åˆ»çš„çŠ¶æ€â€œ\n![Image Name](https://cdn.kesci.com/upload/image/q5ssnlsje7.png?imageView2/0/w/960/h/960)\n\næœ€åä»‹ç»GRUæœ€å…³é”®çš„ä¸€ä¸ªæ­¥éª¤**æ›´æ–°è®°å¿†**é˜¶æ®µã€‚\n\nåœ¨è¿™ä¸ªé˜¶æ®µï¼Œæˆ‘ä»¬åŒæ—¶è¿›è¡Œäº†é—å¿˜äº†è®°å¿†ä¸¤ä¸ªæ­¥éª¤ã€‚æˆ‘ä»¬ä½¿ç”¨äº†å…ˆå‰å¾—åˆ°çš„æ›´æ–°é—¨æ§$z$ï¼ˆupdate gateï¼‰ã€‚\næ›´æ–°è¡¨è¾¾å¼ï¼š$h^t = z âŠ™h^{t-1}+(1-z)âŠ™h^{'}$\n\né¦–å…ˆå†æ¬¡å¼ºè°ƒä¸€ä¸‹ï¼Œé—¨æ§ä¿¡å·ï¼ˆzï¼‰çš„èŒƒå›´ä¸º0~1ã€‚é—¨æ§ä¿¡å·è¶Šæ¥è¿‘1ï¼Œä»£è¡¨â€è®°å¿†â€œä¸‹æ¥çš„æ•°æ®è¶Šå¤šï¼›è€Œè¶Šæ¥è¿‘0åˆ™ä»£è¡¨â€é—å¿˜â€œçš„è¶Šå¤šã€‚\n\nGRUå¾ˆèªæ˜çš„ä¸€ç‚¹å°±åœ¨äºï¼Œæˆ‘ä»¬ä½¿ç”¨äº†åŒä¸€ä¸ªé—¨æ§$z$å°±åŒæ—¶å¯ä»¥è¿›è¡Œé—å¿˜å’Œé€‰æ‹©è®°å¿†ï¼ˆLSTMåˆ™è¦ä½¿ç”¨å¤šä¸ªé—¨æ§ï¼‰ã€‚\n\n**$z âŠ™h^{t-1}$**ï¼šè¡¨ç¤ºå¯¹åŸæœ¬éšè—çŠ¶æ€çš„é€‰æ‹©æ€§â€œé—å¿˜â€ã€‚è¿™é‡Œçš„$z$å¯ä»¥æƒ³è±¡æˆé—å¿˜é—¨ï¼ˆforget gateï¼‰ï¼Œå¿˜è®°$h^{t-1}$ç»´åº¦ä¸­ä¸€äº›ä¸é‡è¦çš„ä¿¡æ¯ã€‚\n\n**$(1-z)âŠ™h'$** ï¼š è¡¨ç¤ºå¯¹åŒ…å«å½“å‰èŠ‚ç‚¹ä¿¡æ¯çš„$h'$è¿›è¡Œé€‰æ‹©æ€§â€è®°å¿†â€œã€‚ä¸ä¸Šé¢ç±»ä¼¼ï¼Œè¿™é‡Œçš„$(1-z)$åŒç†ä¼šå¿˜è®°$h'$ ç»´åº¦ä¸­çš„ä¸€äº›ä¸é‡è¦çš„ä¿¡æ¯ã€‚æˆ–è€…ï¼Œè¿™é‡Œæˆ‘ä»¬æ›´åº”å½“çœ‹åšæ˜¯å¯¹h'$ç»´åº¦ä¸­çš„æŸäº›ä¿¡æ¯è¿›è¡Œé€‰æ‹©ã€‚\n\n**$h^t = z âŠ™h^{t-1}+(1-z)âŠ™h^{'}$**:ç»“åˆä¸Šè¿°ï¼Œè¿™ä¸€æ­¥çš„æ“ä½œå°±æ˜¯å¿˜è®°ä¼ é€’ä¸‹æ¥çš„ $h^{t-1}$ä¸­çš„æŸäº›ç»´åº¦ä¿¡æ¯ï¼Œå¹¶åŠ å…¥å½“å‰èŠ‚ç‚¹è¾“å…¥çš„æŸäº›ç»´åº¦ä¿¡æ¯ã€‚\nå¯ä»¥çœ‹åˆ°ï¼Œè¿™é‡Œçš„é—å¿˜$z$å’Œé€‰æ‹©$(1-z)$æ˜¯è”åŠ¨çš„ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¯¹äºä¼ é€’è¿›æ¥çš„ç»´åº¦ä¿¡æ¯ï¼Œæˆ‘ä»¬ä¼šè¿›è¡Œé€‰æ‹©æ€§é—å¿˜ï¼Œåˆ™é—å¿˜äº†å¤šå°‘æƒé‡ ï¼ˆzï¼‰ï¼Œæˆ‘ä»¬å°±ä¼šä½¿ç”¨åŒ…å«å½“å‰è¾“å…¥çš„$h'$ä¸­æ‰€å¯¹åº”çš„æƒé‡è¿›è¡Œå¼¥è¡¥(1-z)ã€‚ä»¥ä¿æŒä¸€ç§â€æ’å®šâ€œçŠ¶æ€ã€‚\n\n"},{"metadata":{"id":"EC1D378FA5B6461F889253B7F7C9DE1C","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"##åˆå§‹åŒ–å‚æ•°\nnum_inputs, num_hiddens, num_outputs = vocab_size, 256, vocab_size\nprint('will use', device)\n\ndef get_params():  \n    def _one(shape):\n        ts = torch.tensor(np.random.normal(0, 0.01, size=shape), device=device, dtype=torch.float32) #æ­£æ€åˆ†å¸ƒ\n        return torch.nn.Parameter(ts, requires_grad=True)\n    def _three():\n        return (_one((num_inputs, num_hiddens)),\n                _one((num_hiddens, num_hiddens)),\n                torch.nn.Parameter(torch.zeros(num_hiddens, device=device, dtype=torch.float32), requires_grad=True))\n     \n    W_xz, W_hz, b_z = _three()  # æ›´æ–°é—¨å‚æ•°\n    W_xr, W_hr, b_r = _three()  # é‡ç½®é—¨å‚æ•°\n    W_xh, W_hh, b_h = _three()  # å€™é€‰éšè—çŠ¶æ€å‚æ•°\n    \n    # è¾“å‡ºå±‚å‚æ•°\n    W_hq = _one((num_hiddens, num_outputs))\n    b_q = torch.nn.Parameter(torch.zeros(num_outputs, device=device, dtype=torch.float32), requires_grad=True)\n    return nn.ParameterList([W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q])\n\ndef init_gru_state(batch_size, num_hiddens, device):   #éšè—çŠ¶æ€åˆå§‹åŒ–\n    return (torch.zeros((batch_size, num_hiddens), device=device), )\n    \n##GRUæ¨¡å‹\ndef gru(inputs, state, params):\n    W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params\n    H, = state\n    outputs = []\n    for X in inputs:\n        Z = torch.sigmoid(torch.matmul(X, W_xz) + torch.matmul(H, W_hz) + b_z)\n        R = torch.sigmoid(torch.matmul(X, W_xr) + torch.matmul(H, W_hr) + b_r)\n        H_tilda = torch.tanh(torch.matmul(X, W_xh) + R * torch.matmul(H, W_hh) + b_h)\n        H = Z * H + (1 - Z) * H_tilda\n        Y = torch.matmul(H, W_hq) + b_q\n        outputs.append(Y)\n    return outputs, (H,)","execution_count":2},{"metadata":{"id":"7E4B327C87A14B5D8FF1D8A36DE57241","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"### LSTM\né•¿çŸ­æœŸè®°å¿†ï¼ˆLong short-term memory, LSTMï¼‰æ˜¯ä¸€ç§ç‰¹æ®Šçš„RNNï¼Œä¸»è¦æ˜¯ä¸ºäº†è§£å†³é•¿åºåˆ—è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸é—®é¢˜ã€‚ç®€å•æ¥è¯´ï¼Œå°±æ˜¯ç›¸æ¯”æ™®é€šçš„RNNï¼ŒLSTMèƒ½å¤Ÿåœ¨æ›´é•¿çš„åºåˆ—ä¸­æœ‰æ›´å¥½çš„è¡¨ç°ã€‚\n\né—å¿˜é—¨:æ§åˆ¶ä¸Šä¸€æ—¶é—´æ­¥çš„è®°å¿†ç»†èƒ \nè¾“å…¥é—¨:æ§åˆ¶å½“å‰æ—¶é—´æ­¥çš„è¾“å…¥  \nè¾“å‡ºé—¨:æ§åˆ¶ä»è®°å¿†ç»†èƒåˆ°éšè—çŠ¶æ€  \nè®°å¿†ç»†èƒï¼šâ¼€ç§ç‰¹æ®Šçš„éšè—çŠ¶æ€çš„ä¿¡æ¯çš„æµåŠ¨ \n\n- **LSTMç»“æ„**\n\n![Image Name](https://cdn.kesci.com/upload/image/q5stl6xcdz.png?imageView2/0/w/960/h/960)\n\n\n![Image Name](https://cdn.kesci.com/upload/image/q5stmqibvz.png?imageView2/0/w/960/h/960)\n\nä»¥ä¸Šï¼Œå°±æ˜¯LSTMçš„å†…éƒ¨ç»“æ„ã€‚é€šè¿‡é—¨æ§çŠ¶æ€æ¥æ§åˆ¶ä¼ è¾“çŠ¶æ€ï¼Œè®°ä½éœ€è¦é•¿æ—¶é—´è®°å¿†çš„ï¼Œå¿˜è®°ä¸é‡è¦çš„ä¿¡æ¯ï¼›è€Œä¸åƒæ™®é€šçš„RNNé‚£æ ·åªèƒ½å¤Ÿâ€œå‘†èŒâ€åœ°ä»…æœ‰ä¸€ç§è®°å¿†å åŠ æ–¹å¼ã€‚å¯¹å¾ˆå¤šéœ€è¦â€œé•¿æœŸè®°å¿†â€çš„ä»»åŠ¡æ¥è¯´ï¼Œå°¤å…¶å¥½ç”¨ã€‚\n\nä½†ä¹Ÿå› ä¸ºå¼•å…¥äº†å¾ˆå¤šå†…å®¹ï¼Œå¯¼è‡´å‚æ•°å˜å¤šï¼Œä¹Ÿä½¿å¾—è®­ç»ƒéš¾åº¦åŠ å¤§äº†å¾ˆå¤šã€‚å› æ­¤å¾ˆå¤šæ—¶å€™æˆ‘ä»¬å¾€å¾€ä¼šä½¿ç”¨æ•ˆæœå’ŒLSTMç›¸å½“ä½†å‚æ•°æ›´å°‘çš„GRUæ¥æ„å»ºå¤§è®­ç»ƒé‡çš„æ¨¡å‹ã€‚"},{"metadata":{"id":"40BE5EC1E44E4C7293C5E188B5AA8500","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"##åˆå§‹åŒ–å‚æ•°ã€éšå±‚ã€æ¨¡å‹å®šä¹‰\ndef get_params():\n    def _one(shape):\n        ts = torch.tensor(np.random.normal(0, 0.01, size=shape), device=device, dtype=torch.float32)\n        return torch.nn.Parameter(ts, requires_grad=True)\n    def _three():\n        return (_one((num_inputs, num_hiddens)),\n                _one((num_hiddens, num_hiddens)),\n                torch.nn.Parameter(torch.zeros(num_hiddens, device=device, dtype=torch.float32), requires_grad=True))\n          \n    W_xi, W_hi, b_i = _three()  # è¾“å…¥é—¨å‚æ•°\n    W_xf, W_hf, b_f = _three()  # é—å¿˜é—¨å‚æ•°\n    W_xo, W_ho, b_o = _three()  # è¾“å‡ºé—¨å‚æ•°\n    W_xc, W_hc, b_c = _three()  # å€™é€‰è®°å¿†ç»†èƒå‚æ•°\n          \n    # è¾“å‡ºå±‚å‚æ•°\n    W_hq = _one((num_hiddens, num_outputs))\n    b_q = torch.nn.Parameter(torch.zeros(num_outputs, device=device, dtype=torch.float32), requires_grad=True)\n    return nn.ParameterList([W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q])\n          \n          \ndef init_lstm_state(batch_size, num_hiddens, device):\n    return (torch.zeros((batch_size, num_hiddens), device=device), \n            torch.zeros((batch_size, num_hiddens), device=device))\n                  \n      \ndef lstm(inputs, state, params):\n    [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q] = params\n    (H, C) = state\n    outputs = []\n    for X in inputs:\n        I = torch.sigmoid(torch.matmul(X, W_xi) + torch.matmul(H, W_hi) + b_i)\n        F = torch.sigmoid(torch.matmul(X, W_xf) + torch.matmul(H, W_hf) + b_f)\n        O = torch.sigmoid(torch.matmul(X, W_xo) + torch.matmul(H, W_ho) + b_o)\n        C_tilda = torch.tanh(torch.matmul(X, W_xc) + torch.matmul(H, W_hc) + b_c)\n        C = F * C + I * C_tilda\n        H = O * C.tanh()\n        Y = torch.matmul(H, W_hq) + b_q\n        outputs.append(Y)\n    return outputs, (H, C)","execution_count":3},{"metadata":{"id":"9CA727FD0E904AA39A1C52F018BD37BF","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"### æ·±åº¦å¾ªç¯ç¥ç»ç½‘ç»œ  \n\n![Image Name](https://cdn.kesci.com/upload/image/q5jk3z1hvz.png?imageView2/0/w/320/h/320)\n\n$$\n\\boldsymbol{H}_t^{(1)} = \\phi(\\boldsymbol{X}_t \\boldsymbol{W}_{xh}^{(1)} + \\boldsymbol{H}_{t-1}^{(1)} \\boldsymbol{W}_{hh}^{(1)} + \\boldsymbol{b}_h^{(1)})\\\\\n\\boldsymbol{H}_t^{(\\ell)} = \\phi(\\boldsymbol{H}_t^{(\\ell-1)} \\boldsymbol{W}_{xh}^{(\\ell)} + \\boldsymbol{H}_{t-1}^{(\\ell)} \\boldsymbol{W}_{hh}^{(\\ell)} + \\boldsymbol{b}_h^{(\\ell)})\\\\\n\\boldsymbol{O}_t = \\boldsymbol{H}_t^{(L)} \\boldsymbol{W}_{hq} + \\boldsymbol{b}_q\n$$"},{"metadata":{"id":"D49649152A84435CB8057457658FA456","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"### åŒå‘å¾ªç¯ç¥ç»ç½‘ç»œ \n\n![Image Name](https://cdn.kesci.com/upload/image/q5j8hmgyrz.png?imageView2/0/w/320/h/320)\n\n$$ \n\\begin{aligned} \\overrightarrow{\\boldsymbol{H}}_t &= \\phi(\\boldsymbol{X}_t \\boldsymbol{W}_{xh}^{(f)} + \\overrightarrow{\\boldsymbol{H}}_{t-1} \\boldsymbol{W}_{hh}^{(f)} + \\boldsymbol{b}_h^{(f)})\\\\\n\\overleftarrow{\\boldsymbol{H}}_t &= \\phi(\\boldsymbol{X}_t \\boldsymbol{W}_{xh}^{(b)} + \\overleftarrow{\\boldsymbol{H}}_{t+1} \\boldsymbol{W}_{hh}^{(b)} + \\boldsymbol{b}_h^{(b)}) \\end{aligned} $$\n$$\n\\boldsymbol{H}_t=(\\overrightarrow{\\boldsymbol{H}}_{t}, \\overleftarrow{\\boldsymbol{H}}_t)\n$$\n$$\n\\boldsymbol{O}_t = \\boldsymbol{H}_t \\boldsymbol{W}_{hq} + \\boldsymbol{b}_q\n$$"},{"metadata":{"id":"8CC05C1EB07A41CC9C0A884549B51AC0","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"## æœºå™¨ç¿»è¯‘\næœºå™¨ç¿»è¯‘ï¼ˆMTï¼‰ï¼šå°†ä¸€æ®µæ–‡æœ¬ä»ä¸€ç§è¯­è¨€è‡ªåŠ¨ç¿»è¯‘ä¸ºå¦ä¸€ç§è¯­è¨€ï¼Œç”¨ç¥ç»ç½‘ç»œè§£å†³è¿™ä¸ªé—®é¢˜é€šå¸¸ç§°ä¸ºç¥ç»æœºå™¨ç¿»è¯‘ï¼ˆNMTï¼‰ã€‚\nä¸»è¦ç‰¹å¾ï¼šè¾“å‡ºæ˜¯å•è¯åºåˆ—è€Œä¸æ˜¯å•ä¸ªå•è¯ã€‚ \nå›°éš¾ï¼šè¾“å‡ºåºåˆ—çš„é•¿åº¦å¯èƒ½ä¸æºåºåˆ—çš„é•¿åº¦ä¸åŒã€‚\n### æ•°æ®å¤„ç†\n1.æ•°æ®æ¸…æ´—ï¼šå¤„ç†ä¹±ç ä¸ç©ºæ ¼ã€‚\n2.åˆ†è¯ï¼šå°†å­—ç¬¦ä¸²è½¬æ¢æˆå•è¯ç»„æˆçš„åˆ—è¡¨\n3.å»ºç«‹è¯å…¸ï¼Œå°†å•è¯ç»„æˆçš„åˆ—è¡¨ç¼–ç¨‹å•è¯idç»„æˆçš„åˆ—è¡¨ï¼Œè¿™é‡Œä¼šå¾—åˆ°å¦‚ä¸‹å‡ æ ·ä¸œè¥¿\n\t\t> å»é‡åè¯å…¸ï¼ŒåŠå…¶ä¸­å•è¯å¯¹åº”çš„ç´¢å¼•åˆ—è¡¨\n\t\t> è¿˜å¯ä»¥å¾—åˆ°ç»™å®šç´¢å¼•æ‰¾åˆ°å…¶å¯¹åº”çš„å•è¯çš„åˆ—è¡¨ï¼Œä»¥åŠç»™å®šå•è¯å¾—åˆ°å¯¹åº”ç´¢å¼•çš„å­—å…¸ã€‚\n\t\t> åŸå§‹è¯­æ–™æ‰€æœ‰è¯å¯¹åº”çš„è¯å…¸ç´¢å¼•çš„åˆ—è¡¨\n4.padding:ä¸€ä¸ªbatchä¸­æ‰€æœ‰å¥å­è¾“å…¥é•¿åº¦ä¿æŒä¸€è‡´\n\t```\n\tdef pad(line, max_len, padding_token):\n\t\t\tif len(line) > max_len:\n\t\t\t\t\treturn line[:max_len]\n\t\t\treturn line + [padding_token] * (max_len - len(line))\n\t```\n5.åŠ è½½æ•°æ®ï¼šæ•°æ®ç”Ÿæˆå™¨\n\n### Encoder-Decoder\nencoderï¼šè¾“å…¥åˆ°éšè—çŠ¶æ€  \ndecoderï¼šéšè—çŠ¶æ€åˆ°è¾“å‡º\nå¯¹è¯ç³»ç»Ÿã€ç”Ÿæˆå¼ä»»åŠ¡ã€ç¿»è¯‘\n\n####  Sequence to Sequenceæ¨¡å‹\nseq2seqæ¨¡å‹åŸºäºç¼–ç å™¨-è§£ç å™¨ä½“ç³»ç»“æ„ï¼Œé€šè¿‡åºåˆ—è¾“å…¥ç”Ÿæˆåºåˆ—è¾“å‡ºã€‚ \nç¼–ç å™¨å’Œè§£ç å™¨éƒ½ä½¿ç”¨é€’å½’ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰å¤„ç†å¯å˜é•¿åº¦çš„åºåˆ—è¾“å…¥ã€‚ \nç¼–ç å™¨çš„éšè—çŠ¶æ€ç›´æ¥ç”¨äºåˆå§‹åŒ–è§£ç å™¨çš„éšè—çŠ¶æ€ï¼Œä»¥å°†ä¿¡æ¯ä»ç¼–ç å™¨ä¼ é€’åˆ°è§£ç å™¨ã€‚\n\nè®­ç»ƒ  \n![Image Name](https://cdn.kesci.com/upload/image/q5jc7a53pt.png?imageView2/0/w/640/h/640)\né¢„æµ‹\n![Image Name](https://cdn.kesci.com/upload/image/q5jcecxcba.png?imageView2/0/w/640/h/640)\nå…·ä½“ç»“æ„ï¼š\n![Image Name](https://cdn.kesci.com/upload/image/q5jccjhkii.png?imageView2/0/w/500/h/500)\n\nEncoder\n```\nclass Seq2SeqEncoder(d2l.Encoder):\n    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n                 dropout=0, **kwargs):\n        super(Seq2SeqEncoder, self).__init__(**kwargs)\n        self.num_hiddens=num_hiddens\n        self.num_layers=num_layers\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        self.rnn = nn.LSTM(embed_size,num_hiddens, num_layers, dropout=dropout)\n   \n    def begin_state(self, batch_size, device):\n        return [torch.zeros(size=(self.num_layers, batch_size, self.num_hiddens),  device=device),\n                torch.zeros(size=(self.num_layers, batch_size, self.num_hiddens),  device=device)]\n    def forward(self, X, *args):\n        X = self.embedding(X) # X shape: (batch_size, seq_len, embed_size)\n        X = X.transpose(0, 1)  # RNN needs first axes to be time\n        # state = self.begin_state(X.shape[1], device=X.device)\n        out, state = self.rnn(X)\n        # The shape of out is (seq_len, batch_size, num_hiddens).\n        # state contains the hidden state and the memory cell\n        # of the last time step, the shape is (num_layers, batch_size, num_hiddens)\n        return out, state\n```\nDecoder\n```\nclass Seq2SeqDecoder(d2l.Decoder):\n    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n                 dropout=0, **kwargs):\n        super(Seq2SeqDecoder, self).__init__(**kwargs)\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        self.rnn = nn.LSTM(embed_size,num_hiddens, num_layers, dropout=dropout)\n        self.dense = nn.Linear(num_hiddens,vocab_size)\n\n    def init_state(self, enc_outputs, *args):\n        return enc_outputs[1]\n\n    def forward(self, X, state):\n        X = self.embedding(X).transpose(0, 1)\n        out, state = self.rnn(X, state)\n        # Make the batch to be the first dimension to simplify loss computation.\n        out = self.dense(out).transpose(0, 1)\n        return out, state\n```\n\n### æŸå¤±å‡½æ•°\nè§£ç å™¨çš„è¾“å‡ºæ˜¯ä¸€ä¸ªå’Œè¯å…¸ç»´åº¦ç›¸åŒçš„å‘é‡ï¼Œå…¶æ¯ä¸ªå€¼å¯¹åº”ä¸å‘é‡ç´¢å¼•ä½ç½®å¯¹åº”è¯çš„åˆ†æ•°ï¼Œä¸€èˆ¬æ˜¯é€‰æ‹©åˆ†æ•°æœ€å¤§çš„é‚£ä¸ªè¯ä½œä¸ºæœ€ç»ˆçš„è¾“å‡ºã€‚\nåœ¨è®¡ç®—æŸå¤±å‡½æ•°ä¹‹å‰ï¼Œè¦æŠŠpaddingå»æ‰ï¼Œå› ä¸ºpaddingçš„éƒ¨åˆ†ä¸å‚ä¸è®¡ç®—\n#### åºåˆ—å±è”½\nåºåˆ—æœ‰æ•ˆé•¿åº¦ä¿ç•™ï¼Œæ— æ•ˆé•¿åº¦å¡«å……ä¸ºç‰¹å®švalue\n```\ndef SequenceMask(X, X_len,value=0):\n    maxlen = X.size(1)\n    mask = torch.arange(maxlen)[None, :].to(X_len.device) < X_len[:, None]   \n    X[~mask]=value\n    return X\n```\n#### æŸå¤±å‡½æ•°MaskedSoftmaxCELoss\nåœ¨äº¤å‰ç†µçš„åŸºç¡€ä¸ŠåŠ ä¸ŠSequenceMask\n```\nclass MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n    # pred shape: (batch_size, seq_len, vocab_size)\n    # label shape: (batch_size, seq_len)\n    # valid_length shape: (batch_size, )\n    def forward(self, pred, label, valid_length):\n        # the sample weights shape should be (batch_size, seq_len)\n        weights = torch.ones_like(label)\n        weights = SequenceMask(weights, valid_length).float()\n        self.reduction='none'\n        output=super(MaskedSoftmaxCELoss, self).forward(pred.transpose(1,2), label)\n        return (output*weights).mean(dim=1)\n```\n\n###  Beam Searchæœç´¢ç®—æ³•\ngreedy search:åªè€ƒè™‘å½“å‰æ—¶åˆ»çš„å±€éƒ¨æœ€ä¼˜è§£ï¼Œæ²¡æœ‰è€ƒè™‘å‰åè¯­ä¹‰æ˜¯å¦è¿è´¯ï¼ˆéå…¨å±€æœ€ä¼˜è§£)\nç»´ç‰¹æ¯”ç®—æ³•:é€‰æ‹©æ•´ä½“åˆ†æ•°æœ€é«˜çš„å¥å­ï¼ˆæœç´¢ç©ºé—´å¤ªå¤§ï¼‰\né›†æŸæœç´¢ï¼šç»“åˆäº†greedy searchå’Œç»´ç‰¹æ¯”ç®—æ³•\n![Image Name](https://cdn.kesci.com/upload/image/q5jcia86z1.png?imageView2/0/w/640/h/640)\n"},{"metadata":{"id":"46957AA95325436E97DD9446BB181F5D","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"## æ³¨æ„åŠ›æœºåˆ¶\n### seq2seqçš„ä¸è¶³\nè§£ç å™¨åœ¨å„ä¸ªæ—¶é—´æ­¥ä¾èµ–ç›¸åŒçš„èƒŒæ™¯å˜é‡ï¼ˆcontext vectorï¼‰æ¥è·å–è¾“â¼Šåºåˆ—ä¿¡æ¯ã€‚å½“ç¼–ç å™¨ä¸ºå¾ªç¯ç¥ç»â½¹ç»œæ—¶ï¼ŒèƒŒæ™¯å˜é‡æ¥â¾ƒå®ƒæœ€ç»ˆæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ã€‚å°†æºåºåˆ—è¾“å…¥ä¿¡æ¯ä»¥å¾ªç¯å•ä½çŠ¶æ€ç¼–ç ï¼Œç„¶åå°†å…¶ä¼ é€’ç»™è§£ç å™¨ä»¥ç”Ÿæˆç›®æ ‡åºåˆ—ã€‚ç„¶è€Œè¿™ç§ç»“æ„å­˜åœ¨ç€é—®é¢˜ï¼Œå°¤å…¶æ˜¯RNNæœºåˆ¶å®é™…ä¸­å­˜åœ¨é•¿ç¨‹æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ï¼Œå¯¹äºè¾ƒé•¿çš„å¥å­ï¼Œæˆ‘ä»¬å¾ˆéš¾å¯„å¸Œæœ›äºå°†è¾“å…¥çš„åºåˆ—è½¬åŒ–ä¸ºå®šé•¿çš„å‘é‡è€Œä¿å­˜æ‰€æœ‰çš„æœ‰æ•ˆä¿¡æ¯ï¼Œ**æ‰€ä»¥éšç€æ‰€éœ€ç¿»è¯‘å¥å­çš„é•¿åº¦çš„å¢åŠ ï¼Œè¿™ç§ç»“æ„çš„æ•ˆæœä¼šæ˜¾è‘—ä¸‹é™**ã€‚\nä¸æ­¤åŒæ—¶ï¼Œè§£ç çš„ç›®æ ‡è¯è¯­å¯èƒ½åªä¸åŸè¾“å…¥çš„éƒ¨åˆ†è¯è¯­æœ‰å…³ï¼Œè€Œå¹¶ä¸æ˜¯ä¸æ‰€æœ‰çš„è¾“å…¥æœ‰å…³ã€‚ä¾‹å¦‚ï¼Œå½“æŠŠâ€œHello worldâ€ç¿»è¯‘æˆâ€œBonjour le mondeâ€æ—¶ï¼Œâ€œHelloâ€æ˜ å°„æˆâ€œBonjourâ€ï¼Œâ€œworldâ€æ˜ å°„æˆâ€œmondeâ€ã€‚åœ¨seq2seqæ¨¡å‹ä¸­ï¼Œè§£ç å™¨åªèƒ½éšå¼åœ°ä»ç¼–ç å™¨çš„æœ€ç»ˆçŠ¶æ€ä¸­é€‰æ‹©ç›¸åº”çš„ä¿¡æ¯ã€‚ç„¶è€Œï¼Œæ³¨æ„åŠ›æœºåˆ¶å¯ä»¥å°†è¿™ç§é€‰æ‹©è¿‡ç¨‹æ˜¾å¼åœ°å»ºæ¨¡ã€‚\n\n### æ³¨æ„åŠ›æœºåˆ¶æ¡†æ¶\n\nAttention æ˜¯ä¸€ç§é€šç”¨çš„å¸¦æƒæ± åŒ–æ–¹æ³•ï¼Œè¾“å…¥ç”±ä¸¤éƒ¨åˆ†æ„æˆï¼šè¯¢é—®ï¼ˆqueryï¼‰å’Œé”®å€¼å¯¹ï¼ˆkey-value pairsï¼‰ã€‚$ğ¤_ğ‘–âˆˆâ„^{ğ‘‘_ğ‘˜}, ğ¯_ğ‘–âˆˆâ„^{ğ‘‘_ğ‘£}$. Query  $ğªâˆˆâ„^{ğ‘‘_ğ‘}$ , attention layerå¾—åˆ°è¾“å‡ºä¸valueçš„ç»´åº¦ä¸€è‡´ $ğ¨âˆˆâ„^{ğ‘‘_ğ‘£}$. å¯¹äºä¸€ä¸ªqueryæ¥è¯´ï¼Œattention layer ä¼šä¸æ¯ä¸€ä¸ªkeyè®¡ç®—æ³¨æ„åŠ›åˆ†æ•°å¹¶è¿›è¡Œæƒé‡çš„å½’ä¸€åŒ–ï¼Œè¾“å‡ºçš„å‘é‡$o$åˆ™æ˜¯valueçš„åŠ æƒæ±‚å’Œï¼Œè€Œæ¯ä¸ªkeyè®¡ç®—çš„æƒé‡ä¸valueä¸€ä¸€å¯¹åº”ã€‚\n\nä¸ºäº†è®¡ç®—è¾“å‡ºï¼Œæˆ‘ä»¬é¦–å…ˆå‡è®¾æœ‰ä¸€ä¸ªå‡½æ•°$\\alpha$ ç”¨äºè®¡ç®—queryå’Œkeyçš„ç›¸ä¼¼æ€§ï¼Œç„¶åå¯ä»¥è®¡ç®—æ‰€æœ‰çš„ attention scores $a_1, \\ldots, a_n$ by\n$$\na_i = \\alpha(\\mathbf q, \\mathbf k_i).\n$$\næˆ‘ä»¬ä½¿ç”¨ softmaxå‡½æ•° è·å¾—æ³¨æ„åŠ›æƒé‡ï¼š\n$$\nb_1, \\ldots, b_n = \\textrm{softmax}(a_1, \\ldots, a_n).\n$$\næœ€ç»ˆçš„è¾“å‡ºå°±æ˜¯valueçš„åŠ æƒæ±‚å’Œï¼š\n$$\n\\mathbf o = \\sum_{i=1}^n b_i \\mathbf v_i.\n$$\n![Image Name](https://cdn.kesci.com/upload/image/q5km4ooyu2.PNG?imageView2/0/w/960/h/960)\n\nä¸åŒçš„attetion layerçš„åŒºåˆ«åœ¨äºscoreå‡½æ•°çš„é€‰æ‹©ï¼Œåœ¨æœ¬èŠ‚çš„å…¶ä½™éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†è®¨è®ºä¸¤ä¸ªå¸¸ç”¨çš„æ³¨æ„å±‚ Dot-product Attention å’Œ Multilayer Perceptron Attention\n\n\n### ç‚¹ç§¯æ³¨æ„åŠ›\nThe dot product å‡è®¾queryå’Œkeysæœ‰ç›¸åŒçš„ç»´åº¦, å³ $\\forall i, ğª,ğ¤_ğ‘– âˆˆ â„_ğ‘‘ $. é€šè¿‡è®¡ç®—queryå’Œkeyè½¬ç½®çš„ä¹˜ç§¯æ¥è®¡ç®—attention score,é€šå¸¸è¿˜ä¼šé™¤å» $\\sqrt{d}$ å‡å°‘è®¡ç®—å‡ºæ¥çš„scoreå¯¹ç»´åº¦ğ‘‘çš„ä¾èµ–æ€§ï¼Œå¦‚ä¸‹\n$$\nğ›¼(ğª,ğ¤)=âŸ¨ğª,ğ¤âŸ©/ \\sqrt{d} \n$$\nå‡è®¾ $ ğâˆˆâ„^{ğ‘šÃ—ğ‘‘}$ æœ‰ $m$ ä¸ªqueryï¼Œ$ğŠâˆˆâ„^{ğ‘›Ã—ğ‘‘}$ æœ‰ $n$ ä¸ªkeys. æˆ‘ä»¬å¯ä»¥é€šè¿‡çŸ©é˜µè¿ç®—çš„æ–¹å¼è®¡ç®—æ‰€æœ‰ $mn$ ä¸ªscoreï¼š\n$$\nğ›¼(ğ,ğŠ)=ğğŠ^ğ‘‡/\\sqrt{d}\n$$\n ç°åœ¨è®©æˆ‘ä»¬å®ç°è¿™ä¸ªå±‚ï¼Œå®ƒæ”¯æŒä¸€æ‰¹æŸ¥è¯¢å’Œé”®å€¼å¯¹ã€‚æ­¤å¤–ï¼Œå®ƒæ”¯æŒä½œä¸ºæ­£åˆ™åŒ–éšæœºåˆ é™¤ä¸€äº›æ³¨æ„åŠ›æƒé‡.\n ```\n class DotProductAttention(nn.Module): \n    def __init__(self, dropout, **kwargs):\n        super(DotProductAttention, self).__init__(**kwargs)\n        self.dropout = nn.Dropout(dropout)\n\n    # query: (batch_size, #queries, d)\n    # key: (batch_size, #kv_pairs, d)\n    # value: (batch_size, #kv_pairs, dim_v)\n    # valid_length: either (batch_size, ) or (batch_size, xx)\n    def forward(self, query, key, value, valid_length=None):\n        d = query.shape[-1]\n        # set transpose_b=True to swap the last two dimensions of key\n        \n        scores = torch.bmm(query, key.transpose(1,2)) / math.sqrt(d)\n        attention_weights = self.dropout(masked_softmax(scores, valid_length))\n        print(\"attention_weight\\n\",attention_weights)\n        return torch.bmm(attention_weights, value)\n```\n\n### å¤šå±‚æ„ŸçŸ¥æœºæ³¨æ„åŠ›\nåœ¨å¤šå±‚æ„ŸçŸ¥å™¨ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆå°† query and keys æŠ•å½±åˆ°  $â„^â„$ .ä¸ºäº†æ›´å…·ä½“ï¼Œæˆ‘ä»¬å°†å¯ä»¥å­¦ä¹ çš„å‚æ•°åšå¦‚ä¸‹æ˜ å°„ \n$ğ–_ğ‘˜âˆˆâ„^{â„Ã—ğ‘‘_ğ‘˜}$ ,  $ğ–_ğ‘âˆˆâ„^{â„Ã—ğ‘‘_ğ‘}$ , and  $ğ¯âˆˆâ„^h$ . å°†scoreå‡½æ•°å®šä¹‰\n$$\nğ›¼(ğ¤,ğª)=ğ¯^ğ‘‡tanh(ğ–_ğ‘˜ğ¤+ğ–_ğ‘ğª)\n$$\n. \nç„¶åå°†key å’Œ value åœ¨ç‰¹å¾çš„ç»´åº¦ä¸Šåˆå¹¶ï¼ˆconcatenateï¼‰ï¼Œç„¶åé€è‡³ a single hidden layer perceptron è¿™å±‚ä¸­ hidden layer ä¸º  â„  and è¾“å‡ºçš„sizeä¸º 1 .éšå±‚æ¿€æ´»å‡½æ•°ä¸ºtanhï¼Œæ— åç½®.\n```\nclass MLPAttention(nn.Module):  \n    def __init__(self, units,ipt_dim,dropout, **kwargs):\n        super(MLPAttention, self).__init__(**kwargs)\n        # Use flatten=True to keep query's and key's 3-D shapes.\n        self.W_k = nn.Linear(ipt_dim, units, bias=False)\n        self.W_q = nn.Linear(ipt_dim, units, bias=False)\n        self.v = nn.Linear(units, 1, bias=False)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, query, key, value, valid_length):\n        query, key = self.W_k(query), self.W_q(key)\n        #print(\"size\",query.size(),key.size())\n        # expand query to (batch_size, #querys, 1, units), and key to\n        # (batch_size, 1, #kv_pairs, units). Then plus them with broadcast.\n        features = query.unsqueeze(2) + key.unsqueeze(1)\n        #print(\"features:\",features.size())  #--------------å¼€å¯\n        scores = self.v(features).squeeze(-1) \n        attention_weights = self.dropout(masked_softmax(scores, valid_length))\n        return torch.bmm(attention_weights, value)\n```\n\n### å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶çš„Seq2seqæ¨¡å‹\nä¸‹å›¾å±•ç¤ºencoding å’Œdecodingçš„æ¨¡å‹ç»“æ„ï¼Œåœ¨æ—¶é—´æ­¥ä¸ºtçš„æ—¶å€™ã€‚æ­¤åˆ»attention layerä¿å­˜ç€encoderingçœ‹åˆ°çš„æ‰€æœ‰ä¿¡æ¯â€”â€”å³encodingçš„æ¯ä¸€æ­¥è¾“å‡ºã€‚åœ¨decodingé˜¶æ®µï¼Œè§£ç å™¨çš„$t$æ—¶åˆ»çš„éšè—çŠ¶æ€è¢«å½“ä½œqueryï¼Œencoderçš„æ¯ä¸ªæ—¶é—´æ­¥çš„hidden statesä½œä¸ºkeyå’Œvalueè¿›è¡Œattentionèšåˆ. Attetion modelçš„è¾“å‡ºå½“ä½œæˆä¸Šä¸‹æ–‡ä¿¡æ¯context vectorï¼Œå¹¶ä¸è§£ç å™¨è¾“å…¥$D_t$æ‹¼æ¥èµ·æ¥ä¸€èµ·é€åˆ°è§£ç å™¨ï¼š\n\n![Image Name](https://cdn.kesci.com/upload/image/q5km7o8z93.PNG?imageView2/0/w/800/h/800)\n\n$$\nFig1å…·æœ‰æ³¨æ„æœºåˆ¶çš„seq-to-seqæ¨¡å‹è§£ç çš„ç¬¬äºŒæ­¥\n$$\nä¸‹å›¾å±•ç¤ºäº†seq2seqæœºåˆ¶çš„æ‰€ä»¥å±‚çš„å…³ç³»ï¼Œä¸‹é¢å±•ç¤ºäº†encoderå’Œdecoderçš„layerç»“æ„\n\n![Image Name](https://cdn.kesci.com/upload/image/q5km8dihlr.PNG?imageView2/0/w/800/h/800)\n$$\nFig2å…·æœ‰æ³¨æ„æœºåˆ¶çš„seq-to-seqæ¨¡å‹ä¸­å±‚ç»“æ„\n$$\n#### è§£ç å™¨\n   ç”±äºå¸¦æœ‰æ³¨æ„æœºåˆ¶çš„seq2seqçš„ç¼–ç å™¨ä¸å˜ï¼Œæ‰€ä»¥åœ¨æ­¤å¤„æˆ‘ä»¬åªå…³æ³¨è§£ç å™¨ã€‚æˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªMLPæ³¨æ„å±‚(MLPAttention)ï¼Œå®ƒçš„éšè—å¤§å°ä¸è§£ç å™¨ä¸­çš„LSTMå±‚ç›¸åŒã€‚ç„¶åæˆ‘ä»¬é€šè¿‡ä»ç¼–ç å™¨ä¼ é€’ä¸‰ä¸ªå‚æ•°æ¥åˆå§‹åŒ–è§£ç å™¨çš„çŠ¶æ€:\n   \n- the encoder outputs of all timestepsï¼šencoderè¾“å‡ºçš„å„ä¸ªçŠ¶æ€ï¼Œè¢«ç”¨äºattetion layerçš„memoryéƒ¨åˆ†ï¼Œæœ‰ç›¸åŒçš„keyå’Œvalues\n\n- the hidden state of the encoderâ€™s final timestepï¼šç¼–ç å™¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ï¼Œè¢«ç”¨äºåˆå§‹åŒ–decoder çš„hidden state\n\n- the encoder valid length: ç¼–ç å™¨çš„æœ‰æ•ˆé•¿åº¦ï¼Œå€Ÿæ­¤ï¼Œæ³¨æ„å±‚ä¸ä¼šè€ƒè™‘ç¼–ç å™¨è¾“å‡ºä¸­çš„å¡«å……æ ‡è®°ï¼ˆPaddingsï¼‰\n\n   åœ¨è§£ç çš„æ¯ä¸ªæ—¶é—´æ­¥ï¼Œæˆ‘ä»¬ä½¿ç”¨è§£ç å™¨çš„æœ€åä¸€ä¸ªRNNå±‚çš„è¾“å‡ºä½œä¸ºæ³¨æ„å±‚çš„queryã€‚ç„¶åï¼Œå°†æ³¨æ„åŠ›æ¨¡å‹çš„è¾“å‡ºä¸è¾“å…¥åµŒå…¥å‘é‡è¿æ¥èµ·æ¥ï¼Œè¾“å…¥åˆ°RNNå±‚ã€‚è™½ç„¶RNNå±‚éšè—çŠ¶æ€ä¹ŸåŒ…å«æ¥è‡ªè§£ç å™¨çš„å†å²ä¿¡æ¯ï¼Œä½†æ˜¯attention modelçš„è¾“å‡ºæ˜¾å¼åœ°é€‰æ‹©äº†enc_valid_lenä»¥å†…çš„ç¼–ç å™¨è¾“å‡ºï¼Œè¿™æ ·attentionæœºåˆ¶å°±ä¼šå°½å¯èƒ½æ’é™¤å…¶ä»–ä¸ç›¸å…³çš„ä¿¡æ¯ã€‚\n```\nclass Seq2SeqAttentionDecoder(d2l.Decoder):\n    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n                 dropout=0, **kwargs):\n        super(Seq2SeqAttentionDecoder, self).__init__(**kwargs)\n        self.attention_cell = MLPAttention(num_hiddens,num_hiddens, dropout)\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        self.rnn = nn.LSTM(embed_size+ num_hiddens,num_hiddens, num_layers, dropout=dropout)\n        self.dense = nn.Linear(num_hiddens,vocab_size)\n\n    def init_state(self, enc_outputs, enc_valid_len, *args):\n        outputs, hidden_state = enc_outputs\n#         print(\"first:\",outputs.size(),hidden_state[0].size(),hidden_state[1].size())\n        # Transpose outputs to (batch_size, seq_len, hidden_size)\n        return (outputs.permute(1,0,-1), hidden_state, enc_valid_len)\n        #outputs.swapaxes(0, 1)\n        \n    def forward(self, X, state):\n        enc_outputs, hidden_state, enc_valid_len = state\n        #(\"X.size\",X.size())\n        X = self.embedding(X).transpose(0,1)\n#         print(\"Xembeding.size2\",X.size())\n        outputs = []\n        for l, x in enumerate(X):\n#             print(f\"\\n{l}-th token\")\n#             print(\"x.first.size()\",x.size())\n            # query shape: (batch_size, 1, hidden_size)\n            # select hidden state of the last rnn layer as query\n            query = hidden_state[0][-1].unsqueeze(1) # np.expand_dims(hidden_state[0][-1], axis=1)\n            # context has same shape as query\n#             print(\"query enc_outputs, enc_outputs:\\n\",query.size(), enc_outputs.size(), enc_outputs.size())\n            context = self.attention_cell(query, enc_outputs, enc_outputs, enc_valid_len)\n            # Concatenate on the feature dimension\n#             print(\"context.size:\",context.size())\n            x = torch.cat((context, x.unsqueeze(1)), dim=-1)\n            # Reshape x to (1, batch_size, embed_size+hidden_size)\n#             print(\"rnn\",x.size(), len(hidden_state))\n            out, hidden_state = self.rnn(x.transpose(0,1), hidden_state)\n            outputs.append(out)\n        outputs = self.dense(torch.cat(outputs, dim=0))\n        return outputs.transpose(0, 1), [enc_outputs, hidden_state,\n                                        enc_valid_len]\n```\næˆ‘ä»¬å¾—åˆ°äº†ç›¸åŒçš„è§£ç å™¨è¾“å‡ºå½¢çŠ¶ï¼Œä½†æ˜¯çŠ¶æ€ç»“æ„æ”¹å˜äº†ã€‚"},{"metadata":{"id":"A969F1B11EB04891A9BC2AB322873E2C","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"\n"},{"metadata":{"id":"92245AE2951B4894BA5BE0C4D6AA4E4F","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"}},"cell_type":"code","outputs":[],"source":"","execution_count":null},{"metadata":{"id":"0B3BF201030040DB82796568250E7F37","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"code","source":"å‚è€ƒï¼š\nhttps://zhuanlan.zhihu.com/p/32481747\nhttps://zhuanlan.zhihu.com/p/32085405","execution_count":null,"outputs":[]},{"metadata":{"id":"1AF7CEA004554AFCAD84250772D8DF50","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"}},"cell_type":"code","outputs":[],"source":"","execution_count":null}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":0}