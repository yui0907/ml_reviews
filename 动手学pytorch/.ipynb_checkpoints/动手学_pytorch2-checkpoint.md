## æ¨¡å‹é€‰æ‹©ã€è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆ
- **æ¨¡å‹é€‰æ‹©**
	1.**éªŒè¯æ•°æ®é›†**
	ä»ä¸¥æ ¼æ„ä¹‰ä¸Šè®²ï¼Œæµ‹è¯•é›†åªèƒ½åœ¨æ‰€æœ‰è¶…å‚æ•°å’Œæ¨¡å‹å‚æ•°é€‰å®šåä½¿ç”¨ä¸€æ¬¡ã€‚ä¸å¯ä»¥ä½¿ç”¨æµ‹è¯•æ•°æ®é€‰æ‹©æ¨¡å‹ï¼Œå¦‚è°ƒå‚ã€‚ç”±äºæ— æ³•ä»è®­ç»ƒè¯¯å·®ä¼°è®¡æ³›åŒ–è¯¯å·®ï¼Œå› æ­¤ä¹Ÿä¸åº”åªä¾èµ–è®­ç»ƒæ•°æ®é€‰æ‹©æ¨¡å‹ã€‚é‰´äºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥é¢„ç•™ä¸€éƒ¨åˆ†åœ¨è®­ç»ƒæ•°æ®é›†å’Œæµ‹è¯•æ•°æ®é›†ä»¥å¤–çš„æ•°æ®æ¥è¿›è¡Œæ¨¡å‹é€‰æ‹©ã€‚è¿™éƒ¨åˆ†æ•°æ®è¢«ç§°ä¸ºéªŒè¯æ•°æ®é›†ï¼Œç®€ç§°éªŒè¯é›†ï¼ˆvalidation setï¼‰ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä»ç»™å®šçš„è®­ç»ƒé›†ä¸­éšæœºé€‰å–ä¸€å°éƒ¨åˆ†ä½œä¸ºéªŒè¯é›†ï¼Œè€Œå°†å‰©ä½™éƒ¨åˆ†ä½œä¸ºçœŸæ­£çš„è®­ç»ƒé›†ã€‚
	2.**KæŠ˜äº¤å‰éªŒè¯**   
	ç”±äºéªŒè¯æ•°æ®é›†ä¸å‚ä¸æ¨¡å‹è®­ç»ƒï¼Œå½“è®­ç»ƒæ•°æ®ä¸å¤Ÿç”¨æ—¶ï¼Œé¢„ç•™å¤§é‡çš„éªŒè¯æ•°æ®æ˜¾å¾—å¤ªå¥¢ä¾ˆã€‚ä¸€ç§æ”¹å–„çš„æ–¹æ³•æ˜¯KæŠ˜äº¤å‰éªŒè¯ï¼ˆK-fold cross-validationï¼‰ã€‚åœ¨KæŠ˜äº¤å‰éªŒè¯ä¸­ï¼Œæˆ‘ä»¬æŠŠåŸå§‹è®­ç»ƒæ•°æ®é›†åˆ†å‰²æˆKä¸ªä¸é‡åˆçš„å­æ•°æ®é›†ï¼Œç„¶åæˆ‘ä»¬åšKæ¬¡æ¨¡å‹è®­ç»ƒå’ŒéªŒè¯ã€‚æ¯ä¸€æ¬¡ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªå­æ•°æ®é›†éªŒè¯æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨å…¶ä»–K-1ä¸ªå­æ•°æ®é›†æ¥è®­ç»ƒæ¨¡å‹ã€‚åœ¨è¿™Kæ¬¡è®­ç»ƒå’ŒéªŒè¯ä¸­ï¼Œæ¯æ¬¡ç”¨æ¥éªŒè¯æ¨¡å‹çš„å­æ•°æ®é›†éƒ½ä¸åŒã€‚æœ€åï¼Œæˆ‘ä»¬å¯¹è¿™Kæ¬¡è®­ç»ƒè¯¯å·®å’ŒéªŒè¯è¯¯å·®åˆ†åˆ«æ±‚å¹³å‡ã€‚


- **è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆ** 
	æ¨¡å‹è®­ç»ƒä¸­ç»å¸¸å‡ºç°çš„ä¸¤ç±»å…¸å‹é—®é¢˜ï¼š
ä¸€ç±»æ˜¯æ¨¡å‹æ— æ³•å¾—åˆ°è¾ƒä½çš„è®­ç»ƒè¯¯å·®ï¼Œæˆ‘ä»¬å°†è¿™ä¸€ç°è±¡ç§°ä½œæ¬ æ‹Ÿåˆï¼ˆunderfittingï¼‰ï¼›
å¦ä¸€ç±»æ˜¯æ¨¡å‹çš„è®­ç»ƒè¯¯å·®è¿œå°äºå®ƒåœ¨æµ‹è¯•æ•°æ®é›†ä¸Šçš„è¯¯å·®ï¼Œæˆ‘ä»¬ç§°è¯¥ç°è±¡ä¸ºè¿‡æ‹Ÿåˆï¼ˆoverfittingï¼‰ã€‚
åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬è¦å°½å¯èƒ½åŒæ—¶åº”å¯¹æ¬ æ‹Ÿåˆå’Œè¿‡æ‹Ÿåˆã€‚
	1.**æ¨¡å‹å¤æ‚åº¦**
	ç»™å®šä¸€ä¸ªç”±æ ‡é‡æ•°æ®ç‰¹å¾$x$å’Œå¯¹åº”çš„æ ‡é‡æ ‡ç­¾$y$ç»„æˆçš„è®­ç»ƒæ•°æ®é›†ï¼Œå¤šé¡¹å¼å‡½æ•°æ‹Ÿåˆçš„ç›®æ ‡æ˜¯æ‰¾ä¸€ä¸ª$K$é˜¶å¤šé¡¹å¼å‡½æ•°
$$
 \hat{y} = b + \sum_{k=1}^K x^k w_k 
$$
æ¥è¿‘ä¼¼ $y$ã€‚åœ¨ä¸Šå¼ä¸­ï¼Œ$w_k$æ˜¯æ¨¡å‹çš„æƒé‡å‚æ•°ï¼Œ$b$æ˜¯åå·®å‚æ•°ã€‚ä¸çº¿æ€§å›å½’ç›¸åŒï¼Œå¤šé¡¹å¼å‡½æ•°æ‹Ÿåˆä¹Ÿä½¿ç”¨å¹³æ–¹æŸå¤±å‡½æ•°ã€‚ç‰¹åˆ«åœ°ï¼Œä¸€é˜¶å¤šé¡¹å¼å‡½æ•°æ‹Ÿåˆåˆå«çº¿æ€§å‡½æ•°æ‹Ÿåˆã€‚
ç»™å®šè®­ç»ƒæ•°æ®é›†ï¼Œæ¨¡å‹å¤æ‚åº¦å’Œè¯¯å·®ä¹‹é—´çš„å…³ç³»ï¼š
![Image Name](https://cdn.kesci.com/upload/image/q5jc27wxoj.png?imageView2/0/w/960/h/960)
	2.**è®­ç»ƒæ•°æ®é›†å¤§å°**
	å½±å“æ¬ æ‹Ÿåˆå’Œè¿‡æ‹Ÿåˆçš„å¦ä¸€ä¸ªé‡è¦å› ç´ æ˜¯è®­ç»ƒæ•°æ®é›†çš„å¤§å°ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œå¦‚æœè®­ç»ƒæ•°æ®é›†ä¸­æ ·æœ¬æ•°è¿‡å°‘ï¼Œç‰¹åˆ«æ˜¯æ¯”æ¨¡å‹å‚æ•°æ•°é‡ï¼ˆæŒ‰å…ƒç´ è®¡ï¼‰æ›´å°‘æ—¶ï¼Œè¿‡æ‹Ÿåˆæ›´å®¹æ˜“å‘ç”Ÿã€‚æ­¤å¤–ï¼Œæ³›åŒ–è¯¯å·®ä¸ä¼šéšè®­ç»ƒæ•°æ®é›†é‡Œæ ·æœ¬æ•°é‡å¢åŠ è€Œå¢å¤§ã€‚å› æ­¤ï¼Œåœ¨è®¡ç®—èµ„æºå…è®¸çš„èŒƒå›´ä¹‹å†…ï¼Œæˆ‘ä»¬é€šå¸¸å¸Œæœ›è®­ç»ƒæ•°æ®é›†å¤§ä¸€äº›ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¨¡å‹å¤æ‚åº¦è¾ƒé«˜æ—¶ï¼Œä¾‹å¦‚å±‚æ•°è¾ƒå¤šçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚
	
- **è§£å†³æ–¹æ³•**
	1.**æ­£åˆ™åŒ–**
	é€šè¿‡ä¸ºæ¨¡å‹æŸå¤±å‡½æ•°æ·»åŠ æƒ©ç½šé¡¹ä½¿å­¦å‡ºçš„æ¨¡å‹å‚æ•°å€¼è¾ƒå°ï¼Œæ˜¯åº”å¯¹è¿‡æ‹Ÿåˆçš„å¸¸ç”¨æ‰‹æ®µã€‚
	$L_2$èŒƒæ•°æ­£åˆ™åŒ–ä»¤**æƒé‡$w_1$å’Œ$w_2$å…ˆè‡ªä¹˜å°äº1çš„æ•°ï¼Œå†å‡å»ä¸å«æƒ©ç½šé¡¹çš„æ¢¯åº¦**ã€‚å› æ­¤ï¼Œ$L_2$èŒƒæ•°æ­£åˆ™åŒ–åˆå«**æƒé‡è¡°å‡**ã€‚æƒé‡è¡°å‡é€šè¿‡æƒ©ç½šç»å¯¹å€¼è¾ƒå¤§çš„æ¨¡å‹å‚æ•°ä¸ºéœ€è¦å­¦ä¹ çš„æ¨¡å‹å¢åŠ äº†é™åˆ¶ï¼Œè¿™å¯èƒ½å¯¹è¿‡æ‹Ÿåˆæœ‰æ•ˆã€‚
	2.**ä¸¢å¼ƒæ³•**
	å¤šå±‚æ„ŸçŸ¥æœºä¸­ç¥ç»ç½‘ç»œå›¾æè¿°äº†ä¸€ä¸ªå•éšè—å±‚çš„å¤šå±‚æ„ŸçŸ¥æœºã€‚å…¶ä¸­è¾“å…¥ä¸ªæ•°ä¸º4ï¼Œéšè—å•å…ƒä¸ªæ•°ä¸º5ï¼Œä¸”éšè—å•å…ƒ$h_i$ï¼ˆ$i=1, \ldots, 5$ï¼‰çš„è®¡ç®—è¡¨è¾¾å¼ä¸º
$$
 h_i = \phi\left(x_1 w_{1i} + x_2 w_{2i} + x_3 w_{3i} + x_4 w_{4i} + b_i\right) 
$$
è¿™é‡Œ$\phi$æ˜¯æ¿€æ´»å‡½æ•°ï¼Œ$x_1, \ldots, x_4$æ˜¯è¾“å…¥ï¼Œéšè—å•å…ƒ$i$çš„æƒé‡å‚æ•°ä¸º$w_{1i}, \ldots, w_{4i}$ï¼Œåå·®å‚æ•°ä¸º$b_i$ã€‚å½“å¯¹è¯¥éšè—å±‚ä½¿ç”¨ä¸¢å¼ƒæ³•æ—¶ï¼Œè¯¥å±‚çš„éšè—å•å…ƒå°†æœ‰ä¸€å®šæ¦‚ç‡è¢«ä¸¢å¼ƒæ‰ã€‚è®¾ä¸¢å¼ƒæ¦‚ç‡ä¸º$p$ï¼Œé‚£ä¹ˆæœ‰$p$çš„æ¦‚ç‡$h_i$ä¼šè¢«æ¸…é›¶ï¼Œæœ‰$1-p$çš„æ¦‚ç‡$h_i$ä¼šé™¤ä»¥$1-p$åšæ‹‰ä¼¸ã€‚ä¸¢å¼ƒæ¦‚ç‡æ˜¯ä¸¢å¼ƒæ³•çš„è¶…å‚æ•°ã€‚å…·ä½“æ¥è¯´ï¼Œè®¾éšæœºå˜é‡$\xi_i$ä¸º0å’Œ1çš„æ¦‚ç‡åˆ†åˆ«ä¸º$p$å’Œ$1-p$ã€‚ä½¿ç”¨ä¸¢å¼ƒæ³•æ—¶æˆ‘ä»¬è®¡ç®—æ–°çš„éšè—å•å…ƒ$h_i'$
$$
 h_i' = \frac{\xi_i}{1-p} h_i 
$$
ç”±äº$E(\xi_i) = 1-p$ï¼Œå› æ­¤
$$
 E(h_i') = \frac{E(\xi_i)}{1-p}h_i = h_i 
$$
å³ä¸¢å¼ƒæ³•ä¸æ”¹å˜å…¶è¾“å…¥çš„æœŸæœ›å€¼ã€‚è®©æˆ‘ä»¬å¯¹ä¹‹å‰å¤šå±‚æ„ŸçŸ¥æœºçš„ç¥ç»ç½‘ç»œä¸­çš„éšè—å±‚ä½¿ç”¨ä¸¢å¼ƒæ³•ï¼Œä¸€ç§å¯èƒ½çš„ç»“æœå¦‚å›¾æ‰€ç¤ºï¼Œå…¶ä¸­$h_2$å’Œ$h_5$è¢«æ¸…é›¶ã€‚è¿™æ—¶è¾“å‡ºå€¼çš„è®¡ç®—ä¸å†ä¾èµ–$h_2$å’Œ$h_5$ï¼Œåœ¨åå‘ä¼ æ’­æ—¶ï¼Œä¸è¿™ä¸¤ä¸ªéšè—å•å…ƒç›¸å…³çš„æƒé‡çš„æ¢¯åº¦å‡ä¸º0ã€‚ç”±äºåœ¨è®­ç»ƒä¸­éšè—å±‚ç¥ç»å…ƒçš„ä¸¢å¼ƒæ˜¯éšæœºçš„ï¼Œå³$h_1, \ldots, h_5$éƒ½æœ‰å¯èƒ½è¢«æ¸…é›¶ï¼Œè¾“å‡ºå±‚çš„è®¡ç®—æ— æ³•è¿‡åº¦ä¾èµ–$h_1, \ldots, h_5$ä¸­çš„ä»»ä¸€ä¸ªï¼Œä»è€Œåœ¨è®­ç»ƒæ¨¡å‹æ—¶èµ·åˆ°æ­£åˆ™åŒ–çš„ä½œç”¨ï¼Œå¹¶å¯ä»¥ç”¨æ¥åº”å¯¹è¿‡æ‹Ÿåˆã€‚åœ¨æµ‹è¯•æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬ä¸ºäº†æ‹¿åˆ°æ›´åŠ ç¡®å®šæ€§çš„ç»“æœï¼Œä¸€èˆ¬ä¸ä½¿ç”¨ä¸¢å¼ƒæ³•
![Image Name](https://cdn.kesci.com/upload/image/q5jd69in3m.png?imageView2/0/w/960/h/960)


```python
def dropout(X, drop_prob):
    X = X.float()
    assert 0 <= drop_prob <= 1
    keep_prob = 1 - drop_prob
    # è¿™ç§æƒ…å†µä¸‹æŠŠå…¨éƒ¨å…ƒç´ éƒ½ä¸¢å¼ƒ
    if keep_prob == 0:
        return torch.zeros_like(X)
    mask = (torch.rand(X.shape) < keep_prob).float()
    
    return mask * X / keep_prob
    
drop_prob1, drop_prob2 = 0.2, 0.5
def net(X, is_training=True):
    X = X.view(-1, num_inputs)
    H1 = (torch.matmul(X, W1) + b1).relu()
    if is_training:  # åªåœ¨è®­ç»ƒæ¨¡å‹æ—¶ä½¿ç”¨ä¸¢å¼ƒæ³•
        H1 = dropout(H1, drop_prob1)  # åœ¨ç¬¬ä¸€å±‚å…¨è¿æ¥åæ·»åŠ ä¸¢å¼ƒå±‚
    H2 = (torch.matmul(H1, W2) + b2).relu()
    if is_training:
        H2 = dropout(H2, drop_prob2)  # åœ¨ç¬¬äºŒå±‚å…¨è¿æ¥åæ·»åŠ ä¸¢å¼ƒå±‚
    return torch.matmul(H2, W3) + b3
```

## æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸
æ·±åº¦æ¨¡å‹æœ‰å…³æ•°å€¼ç¨³å®šæ€§çš„å…¸å‹é—®é¢˜æ˜¯æ¶ˆå¤±ï¼ˆvanishingï¼‰å’Œçˆ†ç‚¸ï¼ˆexplosionï¼‰ã€‚
- **å½“ç¥ç»ç½‘ç»œçš„å±‚æ•°è¾ƒå¤šæ—¶ï¼Œæ¨¡å‹çš„æ•°å€¼ç¨³å®šæ€§å®¹æ˜“å˜å·®ã€‚**
	å‡è®¾ä¸€ä¸ªå±‚æ•°ä¸º$L$çš„å¤šå±‚æ„ŸçŸ¥æœºçš„ç¬¬$l$å±‚$\boldsymbol{H}^{(l)}$çš„æƒé‡å‚æ•°ä¸º$\boldsymbol{W}^{(l)}$ï¼Œè¾“å‡ºå±‚$\boldsymbol{H}^{(L)}$çš„æƒé‡å‚æ•°ä¸º$\boldsymbol{W}^{(L)}$ã€‚ä¸ºäº†ä¾¿äºè®¨è®ºï¼Œä¸è€ƒè™‘åå·®å‚æ•°ï¼Œä¸”è®¾æ‰€æœ‰éšè—å±‚çš„æ¿€æ´»å‡½æ•°ä¸ºæ’ç­‰æ˜ å°„ï¼ˆidentity mappingï¼‰$\phi(x) = x$ã€‚ç»™å®šè¾“å…¥$\boldsymbol{X}$ï¼Œå¤šå±‚æ„ŸçŸ¥æœºçš„ç¬¬$l$å±‚çš„è¾“å‡º$\boldsymbol{H}^{(l)} = \boldsymbol{X} \boldsymbol{W}^{(1)} \boldsymbol{W}^{(2)} \ldots \boldsymbol{W}^{(l)}$ã€‚æ­¤æ—¶ï¼Œå¦‚æœå±‚æ•°$l$è¾ƒå¤§ï¼Œ$\boldsymbol{H}^{(l)}$çš„è®¡ç®—å¯èƒ½ä¼šå‡ºç°è¡°å‡æˆ–çˆ†ç‚¸ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œå‡è®¾è¾“å…¥å’Œæ‰€æœ‰å±‚çš„æƒé‡å‚æ•°éƒ½æ˜¯æ ‡é‡ï¼Œå¦‚æƒé‡å‚æ•°ä¸º0.2å’Œ5ï¼Œå¤šå±‚æ„ŸçŸ¥æœºçš„ç¬¬30å±‚è¾“å‡ºä¸ºè¾“å…¥$\boldsymbol{X}$åˆ†åˆ«ä¸$0.2^{30} \approx 1 \times 10^{-21}$ï¼ˆæ¶ˆå¤±ï¼‰å’Œ$5^{30} \approx 9 \times 10^{20}$ï¼ˆçˆ†ç‚¸ï¼‰çš„ä¹˜ç§¯ã€‚å½“å±‚æ•°è¾ƒå¤šæ—¶ï¼Œæ¢¯åº¦çš„è®¡ç®—ä¹Ÿå®¹æ˜“å‡ºç°æ¶ˆå¤±æˆ–çˆ†ç‚¸ã€‚
	
- **éšæœºåˆå§‹åŒ–æ¨¡å‹å‚æ•°çš„åŸå› **
	å‡è®¾è¾“å‡ºå±‚åªä¿ç•™ä¸€ä¸ªè¾“å‡ºå•å…ƒ$o_1$ï¼ˆåˆ å»$o_2$å’Œ$o_3$ä»¥åŠæŒ‡å‘å®ƒä»¬çš„ç®­å¤´ï¼‰ï¼Œä¸”éšè—å±‚ä½¿ç”¨ç›¸åŒçš„æ¿€æ´»å‡½æ•°ã€‚å¦‚æœå°†æ¯ä¸ªéšè—å•å…ƒçš„å‚æ•°éƒ½åˆå§‹åŒ–ä¸ºç›¸ç­‰çš„å€¼ï¼Œé‚£ä¹ˆåœ¨æ­£å‘ä¼ æ’­æ—¶æ¯ä¸ªéšè—å•å…ƒå°†æ ¹æ®ç›¸åŒçš„è¾“å…¥è®¡ç®—å‡ºç›¸åŒçš„å€¼ï¼Œå¹¶ä¼ é€’è‡³è¾“å‡ºå±‚ã€‚åœ¨åå‘ä¼ æ’­ä¸­ï¼Œæ¯ä¸ªéšè—å•å…ƒçš„å‚æ•°æ¢¯åº¦å€¼ç›¸ç­‰ã€‚å› æ­¤ï¼Œè¿™äº›å‚æ•°åœ¨ä½¿ç”¨åŸºäºæ¢¯åº¦çš„ä¼˜åŒ–ç®—æ³•è¿­ä»£åå€¼ä¾ç„¶ç›¸ç­‰ã€‚ä¹‹åçš„è¿­ä»£ä¹Ÿæ˜¯å¦‚æ­¤ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ— è®ºéšè—å•å…ƒæœ‰å¤šå°‘ï¼Œéšè—å±‚æœ¬è´¨ä¸Šåªæœ‰1ä¸ªéšè—å•å…ƒåœ¨å‘æŒ¥ä½œç”¨ã€‚å› æ­¤ï¼Œæ­£å¦‚åœ¨å‰é¢çš„å®éªŒä¸­æ‰€åšçš„é‚£æ ·ï¼Œæˆ‘ä»¬é€šå¸¸å°†ç¥ç»ç½‘ç»œçš„æ¨¡å‹å‚æ•°ï¼Œç‰¹åˆ«æ˜¯æƒé‡å‚æ•°ï¼Œè¿›è¡Œéšæœºåˆå§‹åŒ–ã€‚
	1. PyTorchçš„é»˜è®¤éšæœºåˆå§‹åŒ– 
	 åœ¨çº¿æ€§å›å½’çš„ç®€æ´å®ç°ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨`torch.nn.init.normal_()`ä½¿æ¨¡å‹`net`çš„æƒé‡å‚æ•°é‡‡ç”¨æ­£æ€åˆ†å¸ƒçš„éšæœºåˆå§‹åŒ–æ–¹å¼ã€‚ä¸è¿‡ï¼ŒPyTorchä¸­`nn.Module`çš„æ¨¡å—å‚æ•°éƒ½é‡‡å–äº†è¾ƒä¸ºåˆç†çš„åˆå§‹åŒ–ç­–ç•¥ï¼ˆä¸åŒç±»å‹çš„layerå…·ä½“é‡‡æ ·çš„å“ªä¸€ç§åˆå§‹åŒ–æ–¹æ³•çš„å¯å‚è€ƒ[æºä»£ç ](https://github.com/pytorch/pytorch/tree/master/torch/nn/modules)ï¼‰ï¼Œå› æ­¤ä¸€èˆ¬ä¸ç”¨æˆ‘ä»¬è€ƒè™‘
	2. Xavieréšæœºåˆå§‹åŒ–
	å‡è®¾æŸå…¨è¿æ¥å±‚çš„è¾“å…¥ä¸ªæ•°ä¸º$a$ï¼Œè¾“å‡ºä¸ªæ•°ä¸º$b$ï¼ŒXavieréšæœºåˆå§‹åŒ–å°†ä½¿è¯¥å±‚ä¸­æƒé‡å‚æ•°çš„æ¯ä¸ªå…ƒç´ éƒ½éšæœºé‡‡æ ·äºå‡åŒ€åˆ†å¸ƒ
$$
U\left(-\sqrt{\frac{6}{a+b}}, \sqrt{\frac{6}{a+b}}\right).
$$
å®ƒçš„è®¾è®¡ä¸»è¦è€ƒè™‘åˆ°ï¼Œæ¨¡å‹å‚æ•°åˆå§‹åŒ–åï¼Œæ¯å±‚è¾“å‡ºçš„æ–¹å·®ä¸è¯¥å—è¯¥å±‚è¾“å…¥ä¸ªæ•°å½±å“ï¼Œä¸”æ¯å±‚æ¢¯åº¦çš„æ–¹å·®ä¹Ÿä¸è¯¥å—è¯¥å±‚è¾“å‡ºä¸ªæ•°å½±å“ã€‚

## å¾ªç¯ç¥ç»ç½‘ç»œè¿›é˜¶

### GRU
RNNå­˜åœ¨çš„é—®é¢˜ï¼šæ¢¯åº¦è¾ƒå®¹æ˜“å‡ºç°è¡°å‡æˆ–çˆ†ç‚¸ï¼ˆBPTTï¼‰  
GRUâ»”æ§å¾ªç¯ç¥ç»â½¹ç»œï¼šæ•æ‰æ—¶é—´åºåˆ—ä¸­æ—¶é—´æ­¥è·ç¦»è¾ƒâ¼¤çš„ä¾èµ–å…³ç³» ,è§£å†³é•¿æœŸè®°å¿†å’Œåå‘ä¼ æ’­ä¸­çš„æ¢¯åº¦ç­‰é—®é¢˜ã€‚
â€¢ é‡ç½®â»”æœ‰åŠ©äºæ•æ‰æ—¶é—´åºåˆ—â¾¥çŸ­æœŸçš„ä¾èµ–å…³ç³»ï¼›  
â€¢ æ›´æ–°â»”æœ‰åŠ©äºæ•æ‰æ—¶é—´åºåˆ—â¾¥â»“æœŸçš„ä¾èµ–å…³ç³»ã€‚ 

- **GRUçš„è¾“å…¥è¾“å‡ºç»“æ„**
GRUçš„è¾“å…¥è¾“å‡ºç»“æ„ä¸æ™®é€šçš„RNNæ˜¯ä¸€æ ·çš„ã€‚
æœ‰ä¸€ä¸ªå½“å‰çš„è¾“å…¥$x^t$ ï¼Œå’Œä¸Šä¸€ä¸ªèŠ‚ç‚¹ä¼ é€’ä¸‹æ¥çš„éšçŠ¶æ€ï¼ˆhidden stateï¼‰$h^{t-1}$ï¼Œè¿™ä¸ªéšçŠ¶æ€åŒ…å«äº†ä¹‹å‰èŠ‚ç‚¹çš„ç›¸å…³ä¿¡æ¯ã€‚
ç»“åˆ$x^t$ å’Œ$h^{t-1}$ï¼ŒGRUä¼šå¾—åˆ°å½“å‰éšè—èŠ‚ç‚¹çš„è¾“å‡º$y^t$ å’Œä¼ é€’ç»™ä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„éšçŠ¶æ€$h^t$ã€‚
![Image Name](https://cdn.kesci.com/upload/image/q5srwnnmv7.png?imageView2/0/w/360/h/360)

- **GRUçš„å†…éƒ¨ç»“æ„**
é¦–å…ˆï¼Œæˆ‘ä»¬å…ˆé€šè¿‡ä¸Šä¸€ä¸ªä¼ è¾“ä¸‹æ¥çš„çŠ¶æ€ $h^{t-1}$ å’Œå½“å‰èŠ‚ç‚¹çš„è¾“å…¥$x^t$ æ¥è·å–ä¸¤ä¸ªé—¨æ§çŠ¶æ€ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå…¶ä¸­$r$æ§åˆ¶é‡ç½®çš„é—¨æ§ï¼ˆreset gateï¼‰ï¼Œ$z$ä¸ºæ§åˆ¶æ›´æ–°çš„é—¨æ§ï¼ˆupdate gateï¼‰ã€‚
![Image Name](https://cdn.kesci.com/upload/image/q5ss7lod3r.png?imageView2/0/w/360/h/360)

å¾—åˆ°é—¨æ§ä¿¡å·ä¹‹åï¼Œé¦–å…ˆä½¿ç”¨é‡ç½®é—¨æ§æ¥å¾—åˆ°â€œé‡ç½®â€ä¹‹åçš„æ•°æ®$h^{t-1'}=h^{t-1}âŠ™r$ ï¼Œå†å°†$h^{t-1'}$ä¸è¾“å…¥ $x^r$ è¿›è¡Œæ‹¼æ¥ï¼Œå†é€šè¿‡ä¸€ä¸ªtanhæ¿€æ´»å‡½æ•°æ¥å°†æ•°æ®æ”¾ç¼©åˆ°-1~1çš„èŒƒå›´å†…ã€‚å³å¾—åˆ°å¦‚ä¸‹å›¾æ‰€ç¤ºçš„$h'$ ã€‚
![Image Name](https://cdn.kesci.com/upload/image/q5ssjfuxhf.png?imageView2/0/w/960/h/960)

è¿™é‡Œçš„$h'$ä¸»è¦æ˜¯åŒ…å«äº†å½“å‰è¾“å…¥çš„$x^t$æ•°æ®ã€‚æœ‰é’ˆå¯¹æ€§åœ°å¯¹$h'$æ·»åŠ åˆ°å½“å‰çš„éšè—çŠ¶æ€ï¼Œç›¸å½“äºâ€è®°å¿†äº†å½“å‰æ—¶åˆ»çš„çŠ¶æ€â€œ
![Image Name](https://cdn.kesci.com/upload/image/q5ssnlsje7.png?imageView2/0/w/960/h/960)

æœ€åä»‹ç»GRUæœ€å…³é”®çš„ä¸€ä¸ªæ­¥éª¤**æ›´æ–°è®°å¿†**é˜¶æ®µã€‚

åœ¨è¿™ä¸ªé˜¶æ®µï¼Œæˆ‘ä»¬åŒæ—¶è¿›è¡Œäº†é—å¿˜äº†è®°å¿†ä¸¤ä¸ªæ­¥éª¤ã€‚æˆ‘ä»¬ä½¿ç”¨äº†å…ˆå‰å¾—åˆ°çš„æ›´æ–°é—¨æ§$z$ï¼ˆupdate gateï¼‰ã€‚
æ›´æ–°è¡¨è¾¾å¼ï¼š$h^t = z âŠ™h^{t-1}+(1-z)âŠ™h^{'}$

é¦–å…ˆå†æ¬¡å¼ºè°ƒä¸€ä¸‹ï¼Œé—¨æ§ä¿¡å·ï¼ˆzï¼‰çš„èŒƒå›´ä¸º0~1ã€‚é—¨æ§ä¿¡å·è¶Šæ¥è¿‘1ï¼Œä»£è¡¨â€è®°å¿†â€œä¸‹æ¥çš„æ•°æ®è¶Šå¤šï¼›è€Œè¶Šæ¥è¿‘0åˆ™ä»£è¡¨â€é—å¿˜â€œçš„è¶Šå¤šã€‚

GRUå¾ˆèªæ˜çš„ä¸€ç‚¹å°±åœ¨äºï¼Œæˆ‘ä»¬ä½¿ç”¨äº†åŒä¸€ä¸ªé—¨æ§$z$å°±åŒæ—¶å¯ä»¥è¿›è¡Œé—å¿˜å’Œé€‰æ‹©è®°å¿†ï¼ˆLSTMåˆ™è¦ä½¿ç”¨å¤šä¸ªé—¨æ§ï¼‰ã€‚

**$z âŠ™h^{t-1}$**ï¼šè¡¨ç¤ºå¯¹åŸæœ¬éšè—çŠ¶æ€çš„é€‰æ‹©æ€§â€œé—å¿˜â€ã€‚è¿™é‡Œçš„$z$å¯ä»¥æƒ³è±¡æˆé—å¿˜é—¨ï¼ˆforget gateï¼‰ï¼Œå¿˜è®°$h^{t-1}$ç»´åº¦ä¸­ä¸€äº›ä¸é‡è¦çš„ä¿¡æ¯ã€‚

**$(1-z)âŠ™h'$** ï¼š è¡¨ç¤ºå¯¹åŒ…å«å½“å‰èŠ‚ç‚¹ä¿¡æ¯çš„$h'$è¿›è¡Œé€‰æ‹©æ€§â€è®°å¿†â€œã€‚ä¸ä¸Šé¢ç±»ä¼¼ï¼Œè¿™é‡Œçš„$(1-z)$åŒç†ä¼šå¿˜è®°$h'$ ç»´åº¦ä¸­çš„ä¸€äº›ä¸é‡è¦çš„ä¿¡æ¯ã€‚æˆ–è€…ï¼Œè¿™é‡Œæˆ‘ä»¬æ›´åº”å½“çœ‹åšæ˜¯å¯¹h'$ç»´åº¦ä¸­çš„æŸäº›ä¿¡æ¯è¿›è¡Œé€‰æ‹©ã€‚

**$h^t = z âŠ™h^{t-1}+(1-z)âŠ™h^{'}$**:ç»“åˆä¸Šè¿°ï¼Œè¿™ä¸€æ­¥çš„æ“ä½œå°±æ˜¯å¿˜è®°ä¼ é€’ä¸‹æ¥çš„ $h^{t-1}$ä¸­çš„æŸäº›ç»´åº¦ä¿¡æ¯ï¼Œå¹¶åŠ å…¥å½“å‰èŠ‚ç‚¹è¾“å…¥çš„æŸäº›ç»´åº¦ä¿¡æ¯ã€‚
å¯ä»¥çœ‹åˆ°ï¼Œè¿™é‡Œçš„é—å¿˜$z$å’Œé€‰æ‹©$(1-z)$æ˜¯è”åŠ¨çš„ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¯¹äºä¼ é€’è¿›æ¥çš„ç»´åº¦ä¿¡æ¯ï¼Œæˆ‘ä»¬ä¼šè¿›è¡Œé€‰æ‹©æ€§é—å¿˜ï¼Œåˆ™é—å¿˜äº†å¤šå°‘æƒé‡ ï¼ˆzï¼‰ï¼Œæˆ‘ä»¬å°±ä¼šä½¿ç”¨åŒ…å«å½“å‰è¾“å…¥çš„$h'$ä¸­æ‰€å¯¹åº”çš„æƒé‡è¿›è¡Œå¼¥è¡¥(1-z)ã€‚ä»¥ä¿æŒä¸€ç§â€æ’å®šâ€œçŠ¶æ€ã€‚




```python
##åˆå§‹åŒ–å‚æ•°
num_inputs, num_hiddens, num_outputs = vocab_size, 256, vocab_size
print('will use', device)

def get_params():  
    def _one(shape):
        ts = torch.tensor(np.random.normal(0, 0.01, size=shape), device=device, dtype=torch.float32) #æ­£æ€åˆ†å¸ƒ
        return torch.nn.Parameter(ts, requires_grad=True)
    def _three():
        return (_one((num_inputs, num_hiddens)),
                _one((num_hiddens, num_hiddens)),
                torch.nn.Parameter(torch.zeros(num_hiddens, device=device, dtype=torch.float32), requires_grad=True))
     
    W_xz, W_hz, b_z = _three()  # æ›´æ–°é—¨å‚æ•°
    W_xr, W_hr, b_r = _three()  # é‡ç½®é—¨å‚æ•°
    W_xh, W_hh, b_h = _three()  # å€™é€‰éšè—çŠ¶æ€å‚æ•°
    
    # è¾“å‡ºå±‚å‚æ•°
    W_hq = _one((num_hiddens, num_outputs))
    b_q = torch.nn.Parameter(torch.zeros(num_outputs, device=device, dtype=torch.float32), requires_grad=True)
    return nn.ParameterList([W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q])

def init_gru_state(batch_size, num_hiddens, device):   #éšè—çŠ¶æ€åˆå§‹åŒ–
    return (torch.zeros((batch_size, num_hiddens), device=device), )
    
##GRUæ¨¡å‹
def gru(inputs, state, params):
    W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params
    H, = state
    outputs = []
    for X in inputs:
        Z = torch.sigmoid(torch.matmul(X, W_xz) + torch.matmul(H, W_hz) + b_z)
        R = torch.sigmoid(torch.matmul(X, W_xr) + torch.matmul(H, W_hr) + b_r)
        H_tilda = torch.tanh(torch.matmul(X, W_xh) + R * torch.matmul(H, W_hh) + b_h)
        H = Z * H + (1 - Z) * H_tilda
        Y = torch.matmul(H, W_hq) + b_q
        outputs.append(Y)
    return outputs, (H,)
```

### LSTM
é•¿çŸ­æœŸè®°å¿†ï¼ˆLong short-term memory, LSTMï¼‰æ˜¯ä¸€ç§ç‰¹æ®Šçš„RNNï¼Œä¸»è¦æ˜¯ä¸ºäº†è§£å†³é•¿åºåˆ—è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸é—®é¢˜ã€‚ç®€å•æ¥è¯´ï¼Œå°±æ˜¯ç›¸æ¯”æ™®é€šçš„RNNï¼ŒLSTMèƒ½å¤Ÿåœ¨æ›´é•¿çš„åºåˆ—ä¸­æœ‰æ›´å¥½çš„è¡¨ç°ã€‚

é—å¿˜é—¨:æ§åˆ¶ä¸Šä¸€æ—¶é—´æ­¥çš„è®°å¿†ç»†èƒ 
è¾“å…¥é—¨:æ§åˆ¶å½“å‰æ—¶é—´æ­¥çš„è¾“å…¥  
è¾“å‡ºé—¨:æ§åˆ¶ä»è®°å¿†ç»†èƒåˆ°éšè—çŠ¶æ€  
è®°å¿†ç»†èƒï¼šâ¼€ç§ç‰¹æ®Šçš„éšè—çŠ¶æ€çš„ä¿¡æ¯çš„æµåŠ¨ 

- **LSTMç»“æ„**

![Image Name](https://cdn.kesci.com/upload/image/q5stl6xcdz.png?imageView2/0/w/960/h/960)


![Image Name](https://cdn.kesci.com/upload/image/q5stmqibvz.png?imageView2/0/w/960/h/960)

ä»¥ä¸Šï¼Œå°±æ˜¯LSTMçš„å†…éƒ¨ç»“æ„ã€‚é€šè¿‡é—¨æ§çŠ¶æ€æ¥æ§åˆ¶ä¼ è¾“çŠ¶æ€ï¼Œè®°ä½éœ€è¦é•¿æ—¶é—´è®°å¿†çš„ï¼Œå¿˜è®°ä¸é‡è¦çš„ä¿¡æ¯ï¼›è€Œä¸åƒæ™®é€šçš„RNNé‚£æ ·åªèƒ½å¤Ÿâ€œå‘†èŒâ€åœ°ä»…æœ‰ä¸€ç§è®°å¿†å åŠ æ–¹å¼ã€‚å¯¹å¾ˆå¤šéœ€è¦â€œé•¿æœŸè®°å¿†â€çš„ä»»åŠ¡æ¥è¯´ï¼Œå°¤å…¶å¥½ç”¨ã€‚

ä½†ä¹Ÿå› ä¸ºå¼•å…¥äº†å¾ˆå¤šå†…å®¹ï¼Œå¯¼è‡´å‚æ•°å˜å¤šï¼Œä¹Ÿä½¿å¾—è®­ç»ƒéš¾åº¦åŠ å¤§äº†å¾ˆå¤šã€‚å› æ­¤å¾ˆå¤šæ—¶å€™æˆ‘ä»¬å¾€å¾€ä¼šä½¿ç”¨æ•ˆæœå’ŒLSTMç›¸å½“ä½†å‚æ•°æ›´å°‘çš„GRUæ¥æ„å»ºå¤§è®­ç»ƒé‡çš„æ¨¡å‹ã€‚


```python
##åˆå§‹åŒ–å‚æ•°ã€éšå±‚ã€æ¨¡å‹å®šä¹‰
def get_params():
    def _one(shape):
        ts = torch.tensor(np.random.normal(0, 0.01, size=shape), device=device, dtype=torch.float32)
        return torch.nn.Parameter(ts, requires_grad=True)
    def _three():
        return (_one((num_inputs, num_hiddens)),
                _one((num_hiddens, num_hiddens)),
                torch.nn.Parameter(torch.zeros(num_hiddens, device=device, dtype=torch.float32), requires_grad=True))
          
    W_xi, W_hi, b_i = _three()  # è¾“å…¥é—¨å‚æ•°
    W_xf, W_hf, b_f = _three()  # é—å¿˜é—¨å‚æ•°
    W_xo, W_ho, b_o = _three()  # è¾“å‡ºé—¨å‚æ•°
    W_xc, W_hc, b_c = _three()  # å€™é€‰è®°å¿†ç»†èƒå‚æ•°
          
    # è¾“å‡ºå±‚å‚æ•°
    W_hq = _one((num_hiddens, num_outputs))
    b_q = torch.nn.Parameter(torch.zeros(num_outputs, device=device, dtype=torch.float32), requires_grad=True)
    return nn.ParameterList([W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q])
          
          
def init_lstm_state(batch_size, num_hiddens, device):
    return (torch.zeros((batch_size, num_hiddens), device=device), 
            torch.zeros((batch_size, num_hiddens), device=device))
                  
      
def lstm(inputs, state, params):
    [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q] = params
    (H, C) = state
    outputs = []
    for X in inputs:
        I = torch.sigmoid(torch.matmul(X, W_xi) + torch.matmul(H, W_hi) + b_i)
        F = torch.sigmoid(torch.matmul(X, W_xf) + torch.matmul(H, W_hf) + b_f)
        O = torch.sigmoid(torch.matmul(X, W_xo) + torch.matmul(H, W_ho) + b_o)
        C_tilda = torch.tanh(torch.matmul(X, W_xc) + torch.matmul(H, W_hc) + b_c)
        C = F * C + I * C_tilda
        H = O * C.tanh()
        Y = torch.matmul(H, W_hq) + b_q
        outputs.append(Y)
    return outputs, (H, C)
```

### æ·±åº¦å¾ªç¯ç¥ç»ç½‘ç»œ  

![Image Name](https://cdn.kesci.com/upload/image/q5jk3z1hvz.png?imageView2/0/w/320/h/320)

$$
\boldsymbol{H}_t^{(1)} = \phi(\boldsymbol{X}_t \boldsymbol{W}_{xh}^{(1)} + \boldsymbol{H}_{t-1}^{(1)} \boldsymbol{W}_{hh}^{(1)} + \boldsymbol{b}_h^{(1)})\\
\boldsymbol{H}_t^{(\ell)} = \phi(\boldsymbol{H}_t^{(\ell-1)} \boldsymbol{W}_{xh}^{(\ell)} + \boldsymbol{H}_{t-1}^{(\ell)} \boldsymbol{W}_{hh}^{(\ell)} + \boldsymbol{b}_h^{(\ell)})\\
\boldsymbol{O}_t = \boldsymbol{H}_t^{(L)} \boldsymbol{W}_{hq} + \boldsymbol{b}_q
$$

### åŒå‘å¾ªç¯ç¥ç»ç½‘ç»œ 

![Image Name](https://cdn.kesci.com/upload/image/q5j8hmgyrz.png?imageView2/0/w/320/h/320)

$$ 
\begin{aligned} \overrightarrow{\boldsymbol{H}}_t &= \phi(\boldsymbol{X}_t \boldsymbol{W}_{xh}^{(f)} + \overrightarrow{\boldsymbol{H}}_{t-1} \boldsymbol{W}_{hh}^{(f)} + \boldsymbol{b}_h^{(f)})\\
\overleftarrow{\boldsymbol{H}}_t &= \phi(\boldsymbol{X}_t \boldsymbol{W}_{xh}^{(b)} + \overleftarrow{\boldsymbol{H}}_{t+1} \boldsymbol{W}_{hh}^{(b)} + \boldsymbol{b}_h^{(b)}) \end{aligned} $$
$$
\boldsymbol{H}_t=(\overrightarrow{\boldsymbol{H}}_{t}, \overleftarrow{\boldsymbol{H}}_t)
$$
$$
\boldsymbol{O}_t = \boldsymbol{H}_t \boldsymbol{W}_{hq} + \boldsymbol{b}_q
$$

## æœºå™¨ç¿»è¯‘
æœºå™¨ç¿»è¯‘ï¼ˆMTï¼‰ï¼šå°†ä¸€æ®µæ–‡æœ¬ä»ä¸€ç§è¯­è¨€è‡ªåŠ¨ç¿»è¯‘ä¸ºå¦ä¸€ç§è¯­è¨€ï¼Œç”¨ç¥ç»ç½‘ç»œè§£å†³è¿™ä¸ªé—®é¢˜é€šå¸¸ç§°ä¸ºç¥ç»æœºå™¨ç¿»è¯‘ï¼ˆNMTï¼‰ã€‚
ä¸»è¦ç‰¹å¾ï¼šè¾“å‡ºæ˜¯å•è¯åºåˆ—è€Œä¸æ˜¯å•ä¸ªå•è¯ã€‚ 
å›°éš¾ï¼šè¾“å‡ºåºåˆ—çš„é•¿åº¦å¯èƒ½ä¸æºåºåˆ—çš„é•¿åº¦ä¸åŒã€‚
### æ•°æ®å¤„ç†
1.æ•°æ®æ¸…æ´—ï¼šå¤„ç†ä¹±ç ä¸ç©ºæ ¼ã€‚
2.åˆ†è¯ï¼šå°†å­—ç¬¦ä¸²è½¬æ¢æˆå•è¯ç»„æˆçš„åˆ—è¡¨
3.å»ºç«‹è¯å…¸ï¼Œå°†å•è¯ç»„æˆçš„åˆ—è¡¨ç¼–ç¨‹å•è¯idç»„æˆçš„åˆ—è¡¨ï¼Œè¿™é‡Œä¼šå¾—åˆ°å¦‚ä¸‹å‡ æ ·ä¸œè¥¿
		> å»é‡åè¯å…¸ï¼ŒåŠå…¶ä¸­å•è¯å¯¹åº”çš„ç´¢å¼•åˆ—è¡¨
		> è¿˜å¯ä»¥å¾—åˆ°ç»™å®šç´¢å¼•æ‰¾åˆ°å…¶å¯¹åº”çš„å•è¯çš„åˆ—è¡¨ï¼Œä»¥åŠç»™å®šå•è¯å¾—åˆ°å¯¹åº”ç´¢å¼•çš„å­—å…¸ã€‚
		> åŸå§‹è¯­æ–™æ‰€æœ‰è¯å¯¹åº”çš„è¯å…¸ç´¢å¼•çš„åˆ—è¡¨
4.padding:ä¸€ä¸ªbatchä¸­æ‰€æœ‰å¥å­è¾“å…¥é•¿åº¦ä¿æŒä¸€è‡´
	```
	def pad(line, max_len, padding_token):
			if len(line) > max_len:
					return line[:max_len]
			return line + [padding_token] * (max_len - len(line))
	```
5.åŠ è½½æ•°æ®ï¼šæ•°æ®ç”Ÿæˆå™¨

### Encoder-Decoder
encoderï¼šè¾“å…¥åˆ°éšè—çŠ¶æ€  
decoderï¼šéšè—çŠ¶æ€åˆ°è¾“å‡º
å¯¹è¯ç³»ç»Ÿã€ç”Ÿæˆå¼ä»»åŠ¡ã€ç¿»è¯‘

####  Sequence to Sequenceæ¨¡å‹
seq2seqæ¨¡å‹åŸºäºç¼–ç å™¨-è§£ç å™¨ä½“ç³»ç»“æ„ï¼Œé€šè¿‡åºåˆ—è¾“å…¥ç”Ÿæˆåºåˆ—è¾“å‡ºã€‚ 
ç¼–ç å™¨å’Œè§£ç å™¨éƒ½ä½¿ç”¨é€’å½’ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰å¤„ç†å¯å˜é•¿åº¦çš„åºåˆ—è¾“å…¥ã€‚ 
ç¼–ç å™¨çš„éšè—çŠ¶æ€ç›´æ¥ç”¨äºåˆå§‹åŒ–è§£ç å™¨çš„éšè—çŠ¶æ€ï¼Œä»¥å°†ä¿¡æ¯ä»ç¼–ç å™¨ä¼ é€’åˆ°è§£ç å™¨ã€‚

è®­ç»ƒ  
![Image Name](https://cdn.kesci.com/upload/image/q5jc7a53pt.png?imageView2/0/w/640/h/640)
é¢„æµ‹
![Image Name](https://cdn.kesci.com/upload/image/q5jcecxcba.png?imageView2/0/w/640/h/640)
å…·ä½“ç»“æ„ï¼š
![Image Name](https://cdn.kesci.com/upload/image/q5jccjhkii.png?imageView2/0/w/500/h/500)

Encoder
```
class Seq2SeqEncoder(d2l.Encoder):
    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,
                 dropout=0, **kwargs):
        super(Seq2SeqEncoder, self).__init__(**kwargs)
        self.num_hiddens=num_hiddens
        self.num_layers=num_layers
        self.embedding = nn.Embedding(vocab_size, embed_size)
        self.rnn = nn.LSTM(embed_size,num_hiddens, num_layers, dropout=dropout)
   
    def begin_state(self, batch_size, device):
        return [torch.zeros(size=(self.num_layers, batch_size, self.num_hiddens),  device=device),
                torch.zeros(size=(self.num_layers, batch_size, self.num_hiddens),  device=device)]
    def forward(self, X, *args):
        X = self.embedding(X) # X shape: (batch_size, seq_len, embed_size)
        X = X.transpose(0, 1)  # RNN needs first axes to be time
        # state = self.begin_state(X.shape[1], device=X.device)
        out, state = self.rnn(X)
        # The shape of out is (seq_len, batch_size, num_hiddens).
        # state contains the hidden state and the memory cell
        # of the last time step, the shape is (num_layers, batch_size, num_hiddens)
        return out, state
```
Decoder
```
class Seq2SeqDecoder(d2l.Decoder):
    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,
                 dropout=0, **kwargs):
        super(Seq2SeqDecoder, self).__init__(**kwargs)
        self.embedding = nn.Embedding(vocab_size, embed_size)
        self.rnn = nn.LSTM(embed_size,num_hiddens, num_layers, dropout=dropout)
        self.dense = nn.Linear(num_hiddens,vocab_size)

    def init_state(self, enc_outputs, *args):
        return enc_outputs[1]

    def forward(self, X, state):
        X = self.embedding(X).transpose(0, 1)
        out, state = self.rnn(X, state)
        # Make the batch to be the first dimension to simplify loss computation.
        out = self.dense(out).transpose(0, 1)
        return out, state
```

### æŸå¤±å‡½æ•°
è§£ç å™¨çš„è¾“å‡ºæ˜¯ä¸€ä¸ªå’Œè¯å…¸ç»´åº¦ç›¸åŒçš„å‘é‡ï¼Œå…¶æ¯ä¸ªå€¼å¯¹åº”ä¸å‘é‡ç´¢å¼•ä½ç½®å¯¹åº”è¯çš„åˆ†æ•°ï¼Œä¸€èˆ¬æ˜¯é€‰æ‹©åˆ†æ•°æœ€å¤§çš„é‚£ä¸ªè¯ä½œä¸ºæœ€ç»ˆçš„è¾“å‡ºã€‚
åœ¨è®¡ç®—æŸå¤±å‡½æ•°ä¹‹å‰ï¼Œè¦æŠŠpaddingå»æ‰ï¼Œå› ä¸ºpaddingçš„éƒ¨åˆ†ä¸å‚ä¸è®¡ç®—
#### åºåˆ—å±è”½
åºåˆ—æœ‰æ•ˆé•¿åº¦ä¿ç•™ï¼Œæ— æ•ˆé•¿åº¦å¡«å……ä¸ºç‰¹å®švalue
```
def SequenceMask(X, X_len,value=0):
    maxlen = X.size(1)
    mask = torch.arange(maxlen)[None, :].to(X_len.device) < X_len[:, None]   
    X[~mask]=value
    return X
```
#### æŸå¤±å‡½æ•°MaskedSoftmaxCELoss
åœ¨äº¤å‰ç†µçš„åŸºç¡€ä¸ŠåŠ ä¸ŠSequenceMask
```
class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):
    # pred shape: (batch_size, seq_len, vocab_size)
    # label shape: (batch_size, seq_len)
    # valid_length shape: (batch_size, )
    def forward(self, pred, label, valid_length):
        # the sample weights shape should be (batch_size, seq_len)
        weights = torch.ones_like(label)
        weights = SequenceMask(weights, valid_length).float()
        self.reduction='none'
        output=super(MaskedSoftmaxCELoss, self).forward(pred.transpose(1,2), label)
        return (output*weights).mean(dim=1)
```

###  Beam Searchæœç´¢ç®—æ³•
greedy search:åªè€ƒè™‘å½“å‰æ—¶åˆ»çš„å±€éƒ¨æœ€ä¼˜è§£ï¼Œæ²¡æœ‰è€ƒè™‘å‰åè¯­ä¹‰æ˜¯å¦è¿è´¯ï¼ˆéå…¨å±€æœ€ä¼˜è§£)
ç»´ç‰¹æ¯”ç®—æ³•:é€‰æ‹©æ•´ä½“åˆ†æ•°æœ€é«˜çš„å¥å­ï¼ˆæœç´¢ç©ºé—´å¤ªå¤§ï¼‰
é›†æŸæœç´¢ï¼šç»“åˆäº†greedy searchå’Œç»´ç‰¹æ¯”ç®—æ³•
![Image Name](https://cdn.kesci.com/upload/image/q5jcia86z1.png?imageView2/0/w/640/h/640)


## æ³¨æ„åŠ›æœºåˆ¶
### seq2seqçš„ä¸è¶³
è§£ç å™¨åœ¨å„ä¸ªæ—¶é—´æ­¥ä¾èµ–ç›¸åŒçš„èƒŒæ™¯å˜é‡ï¼ˆcontext vectorï¼‰æ¥è·å–è¾“â¼Šåºåˆ—ä¿¡æ¯ã€‚å½“ç¼–ç å™¨ä¸ºå¾ªç¯ç¥ç»â½¹ç»œæ—¶ï¼ŒèƒŒæ™¯å˜é‡æ¥â¾ƒå®ƒæœ€ç»ˆæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ã€‚å°†æºåºåˆ—è¾“å…¥ä¿¡æ¯ä»¥å¾ªç¯å•ä½çŠ¶æ€ç¼–ç ï¼Œç„¶åå°†å…¶ä¼ é€’ç»™è§£ç å™¨ä»¥ç”Ÿæˆç›®æ ‡åºåˆ—ã€‚ç„¶è€Œè¿™ç§ç»“æ„å­˜åœ¨ç€é—®é¢˜ï¼Œå°¤å…¶æ˜¯RNNæœºåˆ¶å®é™…ä¸­å­˜åœ¨é•¿ç¨‹æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ï¼Œå¯¹äºè¾ƒé•¿çš„å¥å­ï¼Œæˆ‘ä»¬å¾ˆéš¾å¯„å¸Œæœ›äºå°†è¾“å…¥çš„åºåˆ—è½¬åŒ–ä¸ºå®šé•¿çš„å‘é‡è€Œä¿å­˜æ‰€æœ‰çš„æœ‰æ•ˆä¿¡æ¯ï¼Œ**æ‰€ä»¥éšç€æ‰€éœ€ç¿»è¯‘å¥å­çš„é•¿åº¦çš„å¢åŠ ï¼Œè¿™ç§ç»“æ„çš„æ•ˆæœä¼šæ˜¾è‘—ä¸‹é™**ã€‚
ä¸æ­¤åŒæ—¶ï¼Œè§£ç çš„ç›®æ ‡è¯è¯­å¯èƒ½åªä¸åŸè¾“å…¥çš„éƒ¨åˆ†è¯è¯­æœ‰å…³ï¼Œè€Œå¹¶ä¸æ˜¯ä¸æ‰€æœ‰çš„è¾“å…¥æœ‰å…³ã€‚ä¾‹å¦‚ï¼Œå½“æŠŠâ€œHello worldâ€ç¿»è¯‘æˆâ€œBonjour le mondeâ€æ—¶ï¼Œâ€œHelloâ€æ˜ å°„æˆâ€œBonjourâ€ï¼Œâ€œworldâ€æ˜ å°„æˆâ€œmondeâ€ã€‚åœ¨seq2seqæ¨¡å‹ä¸­ï¼Œè§£ç å™¨åªèƒ½éšå¼åœ°ä»ç¼–ç å™¨çš„æœ€ç»ˆçŠ¶æ€ä¸­é€‰æ‹©ç›¸åº”çš„ä¿¡æ¯ã€‚ç„¶è€Œï¼Œæ³¨æ„åŠ›æœºåˆ¶å¯ä»¥å°†è¿™ç§é€‰æ‹©è¿‡ç¨‹æ˜¾å¼åœ°å»ºæ¨¡ã€‚

### æ³¨æ„åŠ›æœºåˆ¶æ¡†æ¶

Attention æ˜¯ä¸€ç§é€šç”¨çš„å¸¦æƒæ± åŒ–æ–¹æ³•ï¼Œè¾“å…¥ç”±ä¸¤éƒ¨åˆ†æ„æˆï¼šè¯¢é—®ï¼ˆqueryï¼‰å’Œé”®å€¼å¯¹ï¼ˆkey-value pairsï¼‰ã€‚$ğ¤_ğ‘–âˆˆâ„^{ğ‘‘_ğ‘˜}, ğ¯_ğ‘–âˆˆâ„^{ğ‘‘_ğ‘£}$. Query  $ğªâˆˆâ„^{ğ‘‘_ğ‘}$ , attention layerå¾—åˆ°è¾“å‡ºä¸valueçš„ç»´åº¦ä¸€è‡´ $ğ¨âˆˆâ„^{ğ‘‘_ğ‘£}$. å¯¹äºä¸€ä¸ªqueryæ¥è¯´ï¼Œattention layer ä¼šä¸æ¯ä¸€ä¸ªkeyè®¡ç®—æ³¨æ„åŠ›åˆ†æ•°å¹¶è¿›è¡Œæƒé‡çš„å½’ä¸€åŒ–ï¼Œè¾“å‡ºçš„å‘é‡$o$åˆ™æ˜¯valueçš„åŠ æƒæ±‚å’Œï¼Œè€Œæ¯ä¸ªkeyè®¡ç®—çš„æƒé‡ä¸valueä¸€ä¸€å¯¹åº”ã€‚

ä¸ºäº†è®¡ç®—è¾“å‡ºï¼Œæˆ‘ä»¬é¦–å…ˆå‡è®¾æœ‰ä¸€ä¸ªå‡½æ•°$\alpha$ ç”¨äºè®¡ç®—queryå’Œkeyçš„ç›¸ä¼¼æ€§ï¼Œç„¶åå¯ä»¥è®¡ç®—æ‰€æœ‰çš„ attention scores $a_1, \ldots, a_n$ by
$$
a_i = \alpha(\mathbf q, \mathbf k_i).
$$
æˆ‘ä»¬ä½¿ç”¨ softmaxå‡½æ•° è·å¾—æ³¨æ„åŠ›æƒé‡ï¼š
$$
b_1, \ldots, b_n = \textrm{softmax}(a_1, \ldots, a_n).
$$
æœ€ç»ˆçš„è¾“å‡ºå°±æ˜¯valueçš„åŠ æƒæ±‚å’Œï¼š
$$
\mathbf o = \sum_{i=1}^n b_i \mathbf v_i.
$$
![Image Name](https://cdn.kesci.com/upload/image/q5km4ooyu2.PNG?imageView2/0/w/960/h/960)

ä¸åŒçš„attetion layerçš„åŒºåˆ«åœ¨äºscoreå‡½æ•°çš„é€‰æ‹©ï¼Œåœ¨æœ¬èŠ‚çš„å…¶ä½™éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†è®¨è®ºä¸¤ä¸ªå¸¸ç”¨çš„æ³¨æ„å±‚ Dot-product Attention å’Œ Multilayer Perceptron Attention


### ç‚¹ç§¯æ³¨æ„åŠ›
The dot product å‡è®¾queryå’Œkeysæœ‰ç›¸åŒçš„ç»´åº¦, å³ $\forall i, ğª,ğ¤_ğ‘– âˆˆ â„_ğ‘‘ $. é€šè¿‡è®¡ç®—queryå’Œkeyè½¬ç½®çš„ä¹˜ç§¯æ¥è®¡ç®—attention score,é€šå¸¸è¿˜ä¼šé™¤å» $\sqrt{d}$ å‡å°‘è®¡ç®—å‡ºæ¥çš„scoreå¯¹ç»´åº¦ğ‘‘çš„ä¾èµ–æ€§ï¼Œå¦‚ä¸‹
$$
ğ›¼(ğª,ğ¤)=âŸ¨ğª,ğ¤âŸ©/ \sqrt{d} 
$$
å‡è®¾ $ ğâˆˆâ„^{ğ‘šÃ—ğ‘‘}$ æœ‰ $m$ ä¸ªqueryï¼Œ$ğŠâˆˆâ„^{ğ‘›Ã—ğ‘‘}$ æœ‰ $n$ ä¸ªkeys. æˆ‘ä»¬å¯ä»¥é€šè¿‡çŸ©é˜µè¿ç®—çš„æ–¹å¼è®¡ç®—æ‰€æœ‰ $mn$ ä¸ªscoreï¼š
$$
ğ›¼(ğ,ğŠ)=ğğŠ^ğ‘‡/\sqrt{d}
$$
 ç°åœ¨è®©æˆ‘ä»¬å®ç°è¿™ä¸ªå±‚ï¼Œå®ƒæ”¯æŒä¸€æ‰¹æŸ¥è¯¢å’Œé”®å€¼å¯¹ã€‚æ­¤å¤–ï¼Œå®ƒæ”¯æŒä½œä¸ºæ­£åˆ™åŒ–éšæœºåˆ é™¤ä¸€äº›æ³¨æ„åŠ›æƒé‡.
 ```
 class DotProductAttention(nn.Module): 
    def __init__(self, dropout, **kwargs):
        super(DotProductAttention, self).__init__(**kwargs)
        self.dropout = nn.Dropout(dropout)

    # query: (batch_size, #queries, d)
    # key: (batch_size, #kv_pairs, d)
    # value: (batch_size, #kv_pairs, dim_v)
    # valid_length: either (batch_size, ) or (batch_size, xx)
    def forward(self, query, key, value, valid_length=None):
        d = query.shape[-1]
        # set transpose_b=True to swap the last two dimensions of key
        
        scores = torch.bmm(query, key.transpose(1,2)) / math.sqrt(d)
        attention_weights = self.dropout(masked_softmax(scores, valid_length))
        print("attention_weight\n",attention_weights)
        return torch.bmm(attention_weights, value)
```

### å¤šå±‚æ„ŸçŸ¥æœºæ³¨æ„åŠ›
åœ¨å¤šå±‚æ„ŸçŸ¥å™¨ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆå°† query and keys æŠ•å½±åˆ°  $â„^â„$ .ä¸ºäº†æ›´å…·ä½“ï¼Œæˆ‘ä»¬å°†å¯ä»¥å­¦ä¹ çš„å‚æ•°åšå¦‚ä¸‹æ˜ å°„ 
$ğ–_ğ‘˜âˆˆâ„^{â„Ã—ğ‘‘_ğ‘˜}$ ,  $ğ–_ğ‘âˆˆâ„^{â„Ã—ğ‘‘_ğ‘}$ , and  $ğ¯âˆˆâ„^h$ . å°†scoreå‡½æ•°å®šä¹‰
$$
ğ›¼(ğ¤,ğª)=ğ¯^ğ‘‡tanh(ğ–_ğ‘˜ğ¤+ğ–_ğ‘ğª)
$$
. 
ç„¶åå°†key å’Œ value åœ¨ç‰¹å¾çš„ç»´åº¦ä¸Šåˆå¹¶ï¼ˆconcatenateï¼‰ï¼Œç„¶åé€è‡³ a single hidden layer perceptron è¿™å±‚ä¸­ hidden layer ä¸º  â„  and è¾“å‡ºçš„sizeä¸º 1 .éšå±‚æ¿€æ´»å‡½æ•°ä¸ºtanhï¼Œæ— åç½®.
```
class MLPAttention(nn.Module):  
    def __init__(self, units,ipt_dim,dropout, **kwargs):
        super(MLPAttention, self).__init__(**kwargs)
        # Use flatten=True to keep query's and key's 3-D shapes.
        self.W_k = nn.Linear(ipt_dim, units, bias=False)
        self.W_q = nn.Linear(ipt_dim, units, bias=False)
        self.v = nn.Linear(units, 1, bias=False)
        self.dropout = nn.Dropout(dropout)

    def forward(self, query, key, value, valid_length):
        query, key = self.W_k(query), self.W_q(key)
        #print("size",query.size(),key.size())
        # expand query to (batch_size, #querys, 1, units), and key to
        # (batch_size, 1, #kv_pairs, units). Then plus them with broadcast.
        features = query.unsqueeze(2) + key.unsqueeze(1)
        #print("features:",features.size())  #--------------å¼€å¯
        scores = self.v(features).squeeze(-1) 
        attention_weights = self.dropout(masked_softmax(scores, valid_length))
        return torch.bmm(attention_weights, value)
```

### å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶çš„Seq2seqæ¨¡å‹
ä¸‹å›¾å±•ç¤ºencoding å’Œdecodingçš„æ¨¡å‹ç»“æ„ï¼Œåœ¨æ—¶é—´æ­¥ä¸ºtçš„æ—¶å€™ã€‚æ­¤åˆ»attention layerä¿å­˜ç€encoderingçœ‹åˆ°çš„æ‰€æœ‰ä¿¡æ¯â€”â€”å³encodingçš„æ¯ä¸€æ­¥è¾“å‡ºã€‚åœ¨decodingé˜¶æ®µï¼Œè§£ç å™¨çš„$t$æ—¶åˆ»çš„éšè—çŠ¶æ€è¢«å½“ä½œqueryï¼Œencoderçš„æ¯ä¸ªæ—¶é—´æ­¥çš„hidden statesä½œä¸ºkeyå’Œvalueè¿›è¡Œattentionèšåˆ. Attetion modelçš„è¾“å‡ºå½“ä½œæˆä¸Šä¸‹æ–‡ä¿¡æ¯context vectorï¼Œå¹¶ä¸è§£ç å™¨è¾“å…¥$D_t$æ‹¼æ¥èµ·æ¥ä¸€èµ·é€åˆ°è§£ç å™¨ï¼š

![Image Name](https://cdn.kesci.com/upload/image/q5km7o8z93.PNG?imageView2/0/w/800/h/800)

$$
Fig1å…·æœ‰æ³¨æ„æœºåˆ¶çš„seq-to-seqæ¨¡å‹è§£ç çš„ç¬¬äºŒæ­¥
$$
ä¸‹å›¾å±•ç¤ºäº†seq2seqæœºåˆ¶çš„æ‰€ä»¥å±‚çš„å…³ç³»ï¼Œä¸‹é¢å±•ç¤ºäº†encoderå’Œdecoderçš„layerç»“æ„

![Image Name](https://cdn.kesci.com/upload/image/q5km8dihlr.PNG?imageView2/0/w/800/h/800)
$$
Fig2å…·æœ‰æ³¨æ„æœºåˆ¶çš„seq-to-seqæ¨¡å‹ä¸­å±‚ç»“æ„
$$
#### è§£ç å™¨
   ç”±äºå¸¦æœ‰æ³¨æ„æœºåˆ¶çš„seq2seqçš„ç¼–ç å™¨ä¸å˜ï¼Œæ‰€ä»¥åœ¨æ­¤å¤„æˆ‘ä»¬åªå…³æ³¨è§£ç å™¨ã€‚æˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªMLPæ³¨æ„å±‚(MLPAttention)ï¼Œå®ƒçš„éšè—å¤§å°ä¸è§£ç å™¨ä¸­çš„LSTMå±‚ç›¸åŒã€‚ç„¶åæˆ‘ä»¬é€šè¿‡ä»ç¼–ç å™¨ä¼ é€’ä¸‰ä¸ªå‚æ•°æ¥åˆå§‹åŒ–è§£ç å™¨çš„çŠ¶æ€:
   
- the encoder outputs of all timestepsï¼šencoderè¾“å‡ºçš„å„ä¸ªçŠ¶æ€ï¼Œè¢«ç”¨äºattetion layerçš„memoryéƒ¨åˆ†ï¼Œæœ‰ç›¸åŒçš„keyå’Œvalues

- the hidden state of the encoderâ€™s final timestepï¼šç¼–ç å™¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ï¼Œè¢«ç”¨äºåˆå§‹åŒ–decoder çš„hidden state

- the encoder valid length: ç¼–ç å™¨çš„æœ‰æ•ˆé•¿åº¦ï¼Œå€Ÿæ­¤ï¼Œæ³¨æ„å±‚ä¸ä¼šè€ƒè™‘ç¼–ç å™¨è¾“å‡ºä¸­çš„å¡«å……æ ‡è®°ï¼ˆPaddingsï¼‰

   åœ¨è§£ç çš„æ¯ä¸ªæ—¶é—´æ­¥ï¼Œæˆ‘ä»¬ä½¿ç”¨è§£ç å™¨çš„æœ€åä¸€ä¸ªRNNå±‚çš„è¾“å‡ºä½œä¸ºæ³¨æ„å±‚çš„queryã€‚ç„¶åï¼Œå°†æ³¨æ„åŠ›æ¨¡å‹çš„è¾“å‡ºä¸è¾“å…¥åµŒå…¥å‘é‡è¿æ¥èµ·æ¥ï¼Œè¾“å…¥åˆ°RNNå±‚ã€‚è™½ç„¶RNNå±‚éšè—çŠ¶æ€ä¹ŸåŒ…å«æ¥è‡ªè§£ç å™¨çš„å†å²ä¿¡æ¯ï¼Œä½†æ˜¯attention modelçš„è¾“å‡ºæ˜¾å¼åœ°é€‰æ‹©äº†enc_valid_lenä»¥å†…çš„ç¼–ç å™¨è¾“å‡ºï¼Œè¿™æ ·attentionæœºåˆ¶å°±ä¼šå°½å¯èƒ½æ’é™¤å…¶ä»–ä¸ç›¸å…³çš„ä¿¡æ¯ã€‚
```
class Seq2SeqAttentionDecoder(d2l.Decoder):
    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,
                 dropout=0, **kwargs):
        super(Seq2SeqAttentionDecoder, self).__init__(**kwargs)
        self.attention_cell = MLPAttention(num_hiddens,num_hiddens, dropout)
        self.embedding = nn.Embedding(vocab_size, embed_size)
        self.rnn = nn.LSTM(embed_size+ num_hiddens,num_hiddens, num_layers, dropout=dropout)
        self.dense = nn.Linear(num_hiddens,vocab_size)

    def init_state(self, enc_outputs, enc_valid_len, *args):
        outputs, hidden_state = enc_outputs
#         print("first:",outputs.size(),hidden_state[0].size(),hidden_state[1].size())
        # Transpose outputs to (batch_size, seq_len, hidden_size)
        return (outputs.permute(1,0,-1), hidden_state, enc_valid_len)
        #outputs.swapaxes(0, 1)
        
    def forward(self, X, state):
        enc_outputs, hidden_state, enc_valid_len = state
        #("X.size",X.size())
        X = self.embedding(X).transpose(0,1)
#         print("Xembeding.size2",X.size())
        outputs = []
        for l, x in enumerate(X):
#             print(f"\n{l}-th token")
#             print("x.first.size()",x.size())
            # query shape: (batch_size, 1, hidden_size)
            # select hidden state of the last rnn layer as query
            query = hidden_state[0][-1].unsqueeze(1) # np.expand_dims(hidden_state[0][-1], axis=1)
            # context has same shape as query
#             print("query enc_outputs, enc_outputs:\n",query.size(), enc_outputs.size(), enc_outputs.size())
            context = self.attention_cell(query, enc_outputs, enc_outputs, enc_valid_len)
            # Concatenate on the feature dimension
#             print("context.size:",context.size())
            x = torch.cat((context, x.unsqueeze(1)), dim=-1)
            # Reshape x to (1, batch_size, embed_size+hidden_size)
#             print("rnn",x.size(), len(hidden_state))
            out, hidden_state = self.rnn(x.transpose(0,1), hidden_state)
            outputs.append(out)
        outputs = self.dense(torch.cat(outputs, dim=0))
        return outputs.transpose(0, 1), [enc_outputs, hidden_state,
                                        enc_valid_len]
```
æˆ‘ä»¬å¾—åˆ°äº†ç›¸åŒçš„è§£ç å™¨è¾“å‡ºå½¢çŠ¶ï¼Œä½†æ˜¯çŠ¶æ€ç»“æ„æ”¹å˜äº†ã€‚

## å·ç§¯ç¥ç»ç½‘ç»œåŸºç¡€
### äºŒç»´äº’ç›¸å…³è¿ç®—
äºŒç»´äº’ç›¸å…³ï¼ˆcross-correlationï¼‰è¿ç®—çš„è¾“å…¥æ˜¯ä¸€ä¸ªäºŒç»´è¾“å…¥æ•°ç»„å’Œä¸€ä¸ªäºŒç»´æ ¸ï¼ˆkernelï¼‰æ•°ç»„ï¼Œè¾“å‡ºä¹Ÿæ˜¯ä¸€ä¸ªäºŒç»´æ•°ç»„ï¼Œå…¶ä¸­æ ¸æ•°ç»„é€šå¸¸ç§°ä¸ºå·ç§¯æ ¸æˆ–è¿‡æ»¤å™¨ï¼ˆfilterï¼‰ã€‚å·ç§¯æ ¸çš„å°ºå¯¸é€šå¸¸å°äºè¾“å…¥æ•°ç»„ï¼Œå·ç§¯æ ¸åœ¨è¾“å…¥æ•°ç»„ä¸Šæ»‘åŠ¨ï¼Œåœ¨æ¯ä¸ªä½ç½®ä¸Šï¼Œå·ç§¯æ ¸ä¸è¯¥ä½ç½®å¤„çš„è¾“å…¥å­æ•°ç»„æŒ‰å…ƒç´ ç›¸ä¹˜å¹¶æ±‚å’Œï¼Œå¾—åˆ°è¾“å‡ºæ•°ç»„ä¸­ç›¸åº”ä½ç½®çš„å…ƒç´ ã€‚å›¾1å±•ç¤ºäº†ä¸€ä¸ªäº’ç›¸å…³è¿ç®—çš„ä¾‹å­ï¼Œé˜´å½±éƒ¨åˆ†åˆ†åˆ«æ˜¯è¾“å…¥çš„ç¬¬ä¸€ä¸ªè®¡ç®—åŒºåŸŸã€æ ¸æ•°ç»„ä»¥åŠå¯¹åº”çš„è¾“å‡ºã€‚

![Image Name](https://cdn.kesci.com/upload/image/q5nfdbhcw5.png?imageView2/0/w/640/h/640)
$$
\begin{array}{l}{0 \times 0+1 \times 1+3 \times 2+4 \times 3=19} \\ {1 \times 0+2 \times 1+4 \times 2+5 \times 3=25} \\ {3 \times 0+4 \times 1+6 \times 2+7 \times 3=37} \\ {4 \times 0+5 \times 1+7 \times 2+8 \times 3=43}\end{array}
$$

```
def corr2d(X, K):
    H, W = X.shape
    h, w = K.shape
    Y = torch.zeros(H - h + 1, W - w + 1)
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()
    return Y
```
### äºŒç»´å·ç§¯å±‚
äºŒç»´å·ç§¯å±‚å°†è¾“å…¥å’Œå·ç§¯æ ¸åšäº’ç›¸å…³è¿ç®—ï¼Œå¹¶åŠ ä¸Šä¸€ä¸ªæ ‡é‡åç½®æ¥å¾—åˆ°è¾“å‡ºã€‚å·ç§¯å±‚çš„æ¨¡å‹å‚æ•°åŒ…æ‹¬å·ç§¯æ ¸å’Œæ ‡é‡åç½®ã€‚
```
class Conv2D(nn.Module):
    def __init__(self, kernel_size):
        super(Conv2D, self).__init__()
        self.weight = nn.Parameter(torch.randn(kernel_size))
        self.bias = nn.Parameter(torch.randn(1))

    def forward(self, x):
        return corr2d(x, self.weight) + self.bias
```
### äº’ç›¸å…³è¿ç®—ä¸å·ç§¯è¿ç®—

å·ç§¯å±‚å¾—åäºå·ç§¯è¿ç®—ï¼Œä½†å·ç§¯å±‚ä¸­ç”¨åˆ°çš„å¹¶éå·ç§¯è¿ç®—è€Œæ˜¯äº’ç›¸å…³è¿ç®—ã€‚æˆ‘ä»¬å°†æ ¸æ•°ç»„ä¸Šä¸‹ç¿»è½¬ã€å·¦å³ç¿»è½¬ï¼Œå†ä¸è¾“å…¥æ•°ç»„åšäº’ç›¸å…³è¿ç®—ï¼Œè¿™ä¸€è¿‡ç¨‹å°±æ˜¯å·ç§¯è¿ç®—ã€‚ç”±äºå·ç§¯å±‚çš„æ ¸æ•°ç»„æ˜¯å¯å­¦ä¹ çš„ï¼Œæ‰€ä»¥ä½¿ç”¨äº’ç›¸å…³è¿ç®—ä¸ä½¿ç”¨å·ç§¯è¿ç®—å¹¶æ— æœ¬è´¨åŒºåˆ«ã€‚

### ç‰¹å¾å›¾ä¸æ„Ÿå—é‡

äºŒç»´å·ç§¯å±‚è¾“å‡ºçš„äºŒç»´æ•°ç»„å¯ä»¥çœ‹ä½œæ˜¯è¾“å…¥åœ¨ç©ºé—´ç»´åº¦ï¼ˆå®½å’Œé«˜ï¼‰ä¸ŠæŸä¸€çº§çš„è¡¨å¾ï¼Œä¹Ÿå«ç‰¹å¾å›¾ï¼ˆfeature mapï¼‰ã€‚å½±å“å…ƒç´ $x$çš„å‰å‘è®¡ç®—çš„æ‰€æœ‰å¯èƒ½è¾“å…¥åŒºåŸŸï¼ˆå¯èƒ½å¤§äºè¾“å…¥çš„å®é™…å°ºå¯¸ï¼‰å«åš$x$çš„æ„Ÿå—é‡ï¼ˆreceptive fieldï¼‰ã€‚

ä»¥äºŒç»´äº’ç›¸å…³è¿ç®—ä¸ºä¾‹ï¼Œè¾“å…¥ä¸­é˜´å½±éƒ¨åˆ†çš„å››ä¸ªå…ƒç´ æ˜¯è¾“å‡ºä¸­é˜´å½±éƒ¨åˆ†å…ƒç´ çš„æ„Ÿå—é‡ã€‚æˆ‘ä»¬å°†å›¾ä¸­å½¢çŠ¶ä¸º$2 \times 2$çš„è¾“å‡ºè®°ä¸º$Y$ï¼Œå°†$Y$ä¸å¦ä¸€ä¸ªå½¢çŠ¶ä¸º$2 \times 2$çš„æ ¸æ•°ç»„åšäº’ç›¸å…³è¿ç®—ï¼Œè¾“å‡ºå•ä¸ªå…ƒç´ $z$ã€‚é‚£ä¹ˆï¼Œ$z$åœ¨$Y$ä¸Šçš„æ„Ÿå—é‡åŒ…æ‹¬$Y$çš„å…¨éƒ¨å››ä¸ªå…ƒç´ ï¼Œåœ¨è¾“å…¥ä¸Šçš„æ„Ÿå—é‡åŒ…æ‹¬å…¶ä¸­å…¨éƒ¨9ä¸ªå…ƒç´ ã€‚å¯è§ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æ›´æ·±çš„å·ç§¯ç¥ç»ç½‘ç»œä½¿ç‰¹å¾å›¾ä¸­å•ä¸ªå…ƒç´ çš„æ„Ÿå—é‡å˜å¾—æ›´åŠ å¹¿é˜”ï¼Œä»è€Œæ•æ‰è¾“å…¥ä¸Šæ›´å¤§å°ºå¯¸çš„ç‰¹å¾ã€‚

### å¡«å……å’Œæ­¥å¹…
#### å¡«å……

å¡«å……ï¼ˆpaddingï¼‰æ˜¯æŒ‡åœ¨è¾“å…¥é«˜å’Œå®½çš„ä¸¤ä¾§å¡«å……å…ƒç´ ï¼ˆé€šå¸¸æ˜¯0å…ƒç´ ï¼‰ï¼Œå›¾2é‡Œæˆ‘ä»¬åœ¨åŸè¾“å…¥é«˜å’Œå®½çš„ä¸¤ä¾§åˆ†åˆ«æ·»åŠ äº†å€¼ä¸º0çš„å…ƒç´ ã€‚


![Image Name](https://cdn.kesci.com/upload/image/q5nfl6ejy4.png?imageView2/0/w/640/h/640)


å¦‚æœåŸè¾“å…¥çš„é«˜å’Œå®½æ˜¯$n_h$å’Œ$n_w$ï¼Œå·ç§¯æ ¸çš„é«˜å’Œå®½æ˜¯$k_h$å’Œ$k_w$ï¼Œåœ¨é«˜çš„ä¸¤ä¾§ä¸€å…±å¡«å……$p_h$è¡Œï¼Œåœ¨å®½çš„ä¸¤ä¾§ä¸€å…±å¡«å……$p_w$åˆ—ï¼Œåˆ™è¾“å‡ºå½¢çŠ¶ä¸ºï¼š
$$
(n_h+p_h-k_h+1)\times(n_w+p_w-k_w+1)
$$
æˆ‘ä»¬åœ¨å·ç§¯ç¥ç»ç½‘ç»œä¸­ä½¿ç”¨å¥‡æ•°é«˜å®½çš„æ ¸ï¼Œæ¯”å¦‚$3 \times 3$ï¼Œ$5 \times 5$çš„å·ç§¯æ ¸ï¼Œå¯¹äºé«˜åº¦ï¼ˆæˆ–å®½åº¦ï¼‰ä¸ºå¤§å°ä¸º$2 k + 

#### æ­¥å¹…

åœ¨äº’ç›¸å…³è¿ç®—ä¸­ï¼Œå·ç§¯æ ¸åœ¨è¾“å…¥æ•°ç»„ä¸Šæ»‘åŠ¨ï¼Œæ¯æ¬¡æ»‘åŠ¨çš„è¡Œæ•°ä¸åˆ—æ•°å³æ˜¯æ­¥å¹…ï¼ˆstrideï¼‰ã€‚æ­¤å‰æˆ‘ä»¬ä½¿ç”¨çš„æ­¥å¹…éƒ½æ˜¯1ï¼Œä¸‹å›¾å±•ç¤ºäº†åœ¨é«˜ä¸Šæ­¥å¹…ä¸º3ã€åœ¨å®½ä¸Šæ­¥å¹…ä¸º2çš„äºŒç»´äº’ç›¸å…³è¿ç®—ã€‚


![Image Name](https://cdn.kesci.com/upload/image/q5nflohnqg.png?imageView2/0/w/640/h/640)


ä¸€èˆ¬æ¥è¯´ï¼Œå½“é«˜ä¸Šæ­¥å¹…ä¸º$s_h$ï¼Œå®½ä¸Šæ­¥å¹…ä¸º$s_w$æ—¶ï¼Œè¾“å‡ºå½¢çŠ¶ä¸ºï¼š

$$

\lfloor(n_h+p_h-k_h+s_h)/s_h\rfloor \times \lfloor(n_w+p_w-k_w+s_w)/s_w\rfloor

$$


å¦‚æœ$p_h=k_h-1$ï¼Œ$p_w=k_w-1$ï¼Œé‚£ä¹ˆè¾“å‡ºå½¢çŠ¶å°†ç®€åŒ–ä¸º$\lfloor(n_h+s_h-1)/s_h\rfloor \times \lfloor(n_w+s_w-1)/s_w\rfloor$ã€‚æ›´è¿›ä¸€æ­¥ï¼Œå¦‚æœè¾“å…¥çš„é«˜å’Œå®½èƒ½åˆ†åˆ«è¢«é«˜å’Œå®½ä¸Šçš„æ­¥å¹…æ•´é™¤ï¼Œé‚£ä¹ˆè¾“å‡ºå½¢çŠ¶å°†æ˜¯$(n_h / s_h) \times (n_w/s_w)$ã€‚

å½“$p_h = p_w = p$æ—¶ï¼Œæˆ‘ä»¬ç§°å¡«å……ä¸º$p$ï¼›å½“$s_h = s_w = s$æ—¶ï¼Œæˆ‘ä»¬ç§°æ­¥å¹…ä¸º$s$ã€‚1$çš„æ ¸ï¼Œä»¤æ­¥å¹…ä¸º1ï¼Œåœ¨é«˜ï¼ˆæˆ–å®½ï¼‰ä¸¤ä¾§é€‰æ‹©å¤§å°ä¸º$k$çš„å¡«å……ï¼Œä¾¿å¯ä¿æŒè¾“å…¥ä¸è¾“å‡ºå°ºå¯¸ç›¸åŒã€‚


### å¤šè¾“å…¥é€šé“å’Œå¤šè¾“å‡ºé€šé“

ä¹‹å‰çš„è¾“å…¥å’Œè¾“å‡ºéƒ½æ˜¯äºŒç»´æ•°ç»„ï¼Œä½†çœŸå®æ•°æ®çš„ç»´åº¦ç»å¸¸æ›´é«˜ã€‚ä¾‹å¦‚ï¼Œå½©è‰²å›¾åƒåœ¨é«˜å’Œå®½2ä¸ªç»´åº¦å¤–è¿˜æœ‰RGBï¼ˆçº¢ã€ç»¿ã€è“ï¼‰3ä¸ªé¢œè‰²é€šé“ã€‚å‡è®¾å½©è‰²å›¾åƒçš„é«˜å’Œå®½åˆ†åˆ«æ˜¯$h$å’Œ$w$ï¼ˆåƒç´ ï¼‰ï¼Œé‚£ä¹ˆå®ƒå¯ä»¥è¡¨ç¤ºä¸ºä¸€ä¸ª$3 \times h \times w$çš„å¤šç»´æ•°ç»„ï¼Œæˆ‘ä»¬å°†å¤§å°ä¸º3çš„è¿™ä¸€ç»´ç§°ä¸ºé€šé“ï¼ˆchannelï¼‰ç»´ã€‚

#### å¤šè¾“å…¥é€šé“

å·ç§¯å±‚çš„è¾“å…¥å¯ä»¥åŒ…å«å¤šä¸ªé€šé“ï¼Œä¸‹å›¾å±•ç¤ºäº†ä¸€ä¸ªå«2ä¸ªè¾“å…¥é€šé“çš„äºŒç»´äº’ç›¸å…³è®¡ç®—çš„ä¾‹å­ã€‚


![Image Name](https://cdn.kesci.com/upload/image/q5nfmdnwbq.png?imageView2/0/w/640/h/640)

å‡è®¾è¾“å…¥æ•°æ®çš„é€šé“æ•°ä¸º$c_i$ï¼Œå·ç§¯æ ¸å½¢çŠ¶ä¸º$k_h\times k_w$ï¼Œæˆ‘ä»¬ä¸ºæ¯ä¸ªè¾“å…¥é€šé“å„åˆ†é…ä¸€ä¸ªå½¢çŠ¶ä¸º$k_h\times k_w$çš„æ ¸æ•°ç»„ï¼Œå°†$c_i$ä¸ªäº’ç›¸å…³è¿ç®—çš„äºŒç»´è¾“å‡ºæŒ‰é€šé“ç›¸åŠ ï¼Œå¾—åˆ°ä¸€ä¸ªäºŒç»´æ•°ç»„ä½œä¸ºè¾“å‡ºã€‚æˆ‘ä»¬æŠŠ$c_i$ä¸ªæ ¸æ•°ç»„åœ¨é€šé“ç»´ä¸Šè¿ç»“ï¼Œå³å¾—åˆ°ä¸€ä¸ªå½¢çŠ¶ä¸º$c_i\times k_h\times k_w$çš„å·ç§¯æ ¸ã€‚

#### å¤šè¾“å‡ºé€šé“

å·ç§¯å±‚çš„è¾“å‡ºä¹Ÿå¯ä»¥åŒ…å«å¤šä¸ªé€šé“ï¼Œè®¾å·ç§¯æ ¸è¾“å…¥é€šé“æ•°å’Œè¾“å‡ºé€šé“æ•°åˆ†åˆ«ä¸º$c_i$å’Œ$c_o$ï¼Œé«˜å’Œå®½åˆ†åˆ«ä¸º$k_h$å’Œ$k_w$ã€‚å¦‚æœå¸Œæœ›å¾—åˆ°å«å¤šä¸ªé€šé“çš„è¾“å‡ºï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºæ¯ä¸ªè¾“å‡ºé€šé“åˆ†åˆ«åˆ›å»ºå½¢çŠ¶ä¸º$c_i\times k_h\times k_w$çš„æ ¸æ•°ç»„ï¼Œå°†å®ƒä»¬åœ¨è¾“å‡ºé€šé“ç»´ä¸Šè¿ç»“ï¼Œå·ç§¯æ ¸çš„å½¢çŠ¶å³$c_o\times c_i\times k_h\times k_w$ã€‚

å¯¹äºè¾“å‡ºé€šé“çš„å·ç§¯æ ¸ï¼Œæˆ‘ä»¬æä¾›è¿™æ ·ä¸€ç§ç†è§£ï¼Œä¸€ä¸ª$c_i \times k_h \times k_w$çš„æ ¸æ•°ç»„å¯ä»¥æå–æŸç§å±€éƒ¨ç‰¹å¾ï¼Œä½†æ˜¯è¾“å…¥å¯èƒ½å…·æœ‰ç›¸å½“ä¸°å¯Œçš„ç‰¹å¾ï¼Œæˆ‘ä»¬éœ€è¦æœ‰å¤šä¸ªè¿™æ ·çš„$c_i \times k_h \times k_w$çš„æ ¸æ•°ç»„ï¼Œä¸åŒçš„æ ¸æ•°ç»„æå–çš„æ˜¯ä¸åŒçš„ç‰¹å¾ã€‚

### å·ç§¯å±‚ä¸å…¨è¿æ¥å±‚çš„å¯¹æ¯”
äºŒç»´å·ç§¯å±‚ç»å¸¸ç”¨äºå¤„ç†å›¾åƒï¼Œä¸æ­¤å‰çš„å…¨è¿æ¥å±‚ç›¸æ¯”ï¼Œå®ƒä¸»è¦æœ‰ä¸¤ä¸ªä¼˜åŠ¿ï¼š

ä¸€æ˜¯å…¨è¿æ¥å±‚æŠŠå›¾åƒå±•å¹³æˆä¸€ä¸ªå‘é‡ï¼Œåœ¨è¾“å…¥å›¾åƒä¸Šç›¸é‚»çš„å…ƒç´ å¯èƒ½å› ä¸ºå±•å¹³æ“ä½œä¸å†ç›¸é‚»ï¼Œç½‘ç»œéš¾ä»¥æ•æ‰å±€éƒ¨ä¿¡æ¯ã€‚è€Œå·ç§¯å±‚çš„è®¾è®¡ï¼Œå¤©ç„¶åœ°å…·æœ‰æå–å±€éƒ¨ä¿¡æ¯çš„èƒ½åŠ›ã€‚

äºŒæ˜¯å·ç§¯å±‚çš„å‚æ•°é‡æ›´å°‘ã€‚ä¸è€ƒè™‘åç½®çš„æƒ…å†µä¸‹ï¼Œä¸€ä¸ªå½¢çŠ¶ä¸º$(c_i, c_o, h, w)$çš„å·ç§¯æ ¸çš„å‚æ•°é‡æ˜¯$c_i \times c_o \times h \times w$ï¼Œä¸è¾“å…¥å›¾åƒçš„å®½é«˜æ— å…³ã€‚å‡å¦‚ä¸€ä¸ªå·ç§¯å±‚çš„è¾“å…¥å’Œè¾“å‡ºå½¢çŠ¶åˆ†åˆ«æ˜¯$(c_1, h_1, w_1)$å’Œ$(c_2, h_2, w_2)$ï¼Œå¦‚æœè¦ç”¨å…¨è¿æ¥å±‚è¿›è¡Œè¿æ¥ï¼Œå‚æ•°æ•°é‡å°±æ˜¯$c_1 \times c_2 \times h_1 \times w_1 \times h_2 \times w_2$ã€‚ä½¿ç”¨å·ç§¯å±‚å¯ä»¥ä»¥è¾ƒå°‘çš„å‚æ•°æ•°é‡æ¥å¤„ç†æ›´å¤§çš„å›¾åƒã€‚

### æ± åŒ–

#### äºŒç»´æ± åŒ–å±‚

æ± åŒ–å±‚ä¸»è¦ç”¨äºç¼“è§£å·ç§¯å±‚å¯¹ä½ç½®çš„è¿‡åº¦æ•æ„Ÿæ€§ã€‚åŒå·ç§¯å±‚ä¸€æ ·ï¼Œæ± åŒ–å±‚æ¯æ¬¡å¯¹è¾“å…¥æ•°æ®çš„ä¸€ä¸ªå›ºå®šå½¢çŠ¶çª—å£ï¼ˆåˆç§°æ± åŒ–çª—å£ï¼‰ä¸­çš„å…ƒç´ è®¡ç®—è¾“å‡ºï¼Œæ± åŒ–å±‚ç›´æ¥è®¡ç®—æ± åŒ–çª—å£å†…å…ƒç´ çš„æœ€å¤§å€¼æˆ–è€…å¹³å‡å€¼ï¼Œè¯¥è¿ç®—ä¹Ÿåˆ†åˆ«å«åš**æœ€å¤§æ± åŒ–æˆ–å¹³å‡æ± åŒ–**ã€‚ä¸‹å›¾å±•ç¤ºäº†æ± åŒ–çª—å£å½¢çŠ¶ä¸º$2\times 2$çš„æœ€å¤§æ± åŒ–ã€‚


![Image Name](https://cdn.kesci.com/upload/image/q5nfob3odo.png?imageView2/0/w/640/h/640)
$$
\begin{array}{l}{\max (0,1,3,4)=4} \\ {\max (1,2,4,5)=5} \\ {\max (3,4,6,7)=7} \\ {\max (4,5,7,8)=8}\end{array}
$$
äºŒç»´å¹³å‡æ± åŒ–çš„å·¥ä½œåŸç†ä¸äºŒç»´æœ€å¤§æ± åŒ–ç±»ä¼¼ï¼Œä½†å°†æœ€å¤§è¿ç®—ç¬¦æ›¿æ¢æˆå¹³å‡è¿ç®—ç¬¦ã€‚æ± åŒ–çª—å£å½¢çŠ¶ä¸º$p \times q$çš„æ± åŒ–å±‚ç§°ä¸º$p \times q$æ± åŒ–å±‚ï¼Œå…¶ä¸­çš„æ± åŒ–è¿ç®—å«ä½œ$p \times q$æ± åŒ–ã€‚

æ± åŒ–å±‚ä¹Ÿå¯ä»¥åœ¨è¾“å…¥çš„é«˜å’Œå®½ä¸¤ä¾§å¡«å……å¹¶è°ƒæ•´çª—å£çš„ç§»åŠ¨æ­¥å¹…æ¥æ”¹å˜è¾“å‡ºå½¢çŠ¶ã€‚æ± åŒ–å±‚å¡«å……å’Œæ­¥å¹…ä¸å·ç§¯å±‚å¡«å……å’Œæ­¥å¹…çš„å·¥ä½œæœºåˆ¶ä¸€æ ·ã€‚

åœ¨å¤„ç†å¤šé€šé“è¾“å…¥æ•°æ®æ—¶ï¼Œæ± åŒ–å±‚å¯¹æ¯ä¸ªè¾“å…¥é€šé“åˆ†åˆ«æ± åŒ–ï¼Œä½†ä¸ä¼šåƒå·ç§¯å±‚é‚£æ ·å°†å„é€šé“çš„ç»“æœæŒ‰é€šé“ç›¸åŠ ã€‚è¿™æ„å‘³ç€æ± åŒ–å±‚çš„è¾“å‡ºé€šé“æ•°ä¸è¾“å…¥é€šé“æ•°ç›¸ç­‰ã€‚
```
X = torch.arange(32, dtype=torch.float32).view(1, 2, 4, 4)
pool2d = nn.MaxPool2d(kernel_size=3, padding=1, stride=(2, 1))
Y = pool2d(X)
```
å¹³å‡æ± åŒ–å±‚ä½¿ç”¨çš„æ˜¯`nn.AvgPool2d`ï¼Œä½¿ç”¨æ–¹æ³•ä¸`nn.MaxPool2d`ç›¸åŒã€‚

## LeNet æ¨¡å‹
LeNetåˆ†ä¸ºå·ç§¯å±‚å—å’Œå…¨è¿æ¥å±‚å—ä¸¤ä¸ªéƒ¨åˆ†

å·ç§¯å±‚å—é‡Œçš„åŸºæœ¬å•ä½æ˜¯å·ç§¯å±‚åæ¥å¹³å‡æ± åŒ–å±‚ï¼šå·ç§¯å±‚ç”¨æ¥è¯†åˆ«å›¾åƒé‡Œçš„ç©ºé—´æ¨¡å¼ï¼Œå¦‚çº¿æ¡å’Œç‰©ä½“å±€éƒ¨ï¼Œä¹‹åçš„å¹³å‡æ± åŒ–å±‚åˆ™ç”¨æ¥é™ä½å·ç§¯å±‚å¯¹ä½ç½®çš„æ•æ„Ÿæ€§ã€‚

å·ç§¯å±‚å—ç”±ä¸¤ä¸ªè¿™æ ·çš„åŸºæœ¬å•ä½é‡å¤å †å æ„æˆã€‚åœ¨å·ç§¯å±‚å—ä¸­ï¼Œæ¯ä¸ªå·ç§¯å±‚éƒ½ä½¿ç”¨$5 \times 5$çš„çª—å£ï¼Œå¹¶åœ¨è¾“å‡ºä¸Šä½¿ç”¨sigmoidæ¿€æ´»å‡½æ•°ã€‚ç¬¬ä¸€ä¸ªå·ç§¯å±‚è¾“å‡ºé€šé“æ•°ä¸º6ï¼Œç¬¬äºŒä¸ªå·ç§¯å±‚è¾“å‡ºé€šé“æ•°åˆ™å¢åŠ åˆ°16ã€‚

å…¨è¿æ¥å±‚å—å«3ä¸ªå…¨è¿æ¥å±‚ã€‚å®ƒä»¬çš„è¾“å‡ºä¸ªæ•°åˆ†åˆ«æ˜¯120ã€84å’Œ10ï¼Œå…¶ä¸­10ä¸ºè¾“å‡ºçš„ç±»åˆ«ä¸ªæ•°ã€‚

```
#net
class Flatten(torch.nn.Module):  #å±•å¹³æ“ä½œ
    def forward(self, x):
        return x.view(x.shape[0], -1)

class Reshape(torch.nn.Module): #å°†å›¾åƒå¤§å°é‡å®šå‹
    def forward(self, x):
        return x.view(-1,1,28,28)      #(B x C x H x W)
    
net = torch.nn.Sequential(     #Lelet                                                  
    Reshape(),
    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2), #b*1*28*28  =>b*6*28*28
    nn.Sigmoid(),                                                       
    nn.AvgPool2d(kernel_size=2, stride=2),                              #b*6*28*28  =>b*6*14*14
    nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),           #b*6*14*14  =>b*16*10*10
    nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2),                              #b*16*10*10  => b*16*5*5
    Flatten(),                                                          #b*16*5*5   => b*400
    nn.Linear(in_features=16*5*5, out_features=120),
    nn.Sigmoid(),
    nn.Linear(120, 84),
    nn.Sigmoid(),
    nn.Linear(84, 10)
)
#print
X = torch.randn(size=(1,1,28,28), dtype = torch.float32)
for layer in net:
    X = layer(X)
    print(layer.__class__.__name__,'output shape: \t',X.shape)
'''
Reshape output shape: 	 torch.Size([1, 1, 28, 28])
Conv2d output shape: 	 torch.Size([1, 6, 28, 28])
Sigmoid output shape: 	 torch.Size([1, 6, 28, 28])
AvgPool2d output shape: 	 torch.Size([1, 6, 14, 14])
Conv2d output shape: 	 torch.Size([1, 16, 10, 10])
Sigmoid output shape: 	 torch.Size([1, 16, 10, 10])
AvgPool2d output shape: 	 torch.Size([1, 16, 5, 5])
Flatten output shape: 	 torch.Size([1, 400])
Linear output shape: 	 torch.Size([1, 120])
Sigmoid output shape: 	 torch.Size([1, 120])
Linear output shape: 	 torch.Size([1, 84])
Sigmoid output shape: 	 torch.Size([1, 84])
Linear output shape: 	 torch.Size([1, 10])
'''
```

å·ç§¯å±‚ç”±äºä½¿ç”¨é«˜å’Œå®½å‡ä¸º5çš„å·ç§¯æ ¸ï¼Œä»è€Œå°†é«˜å’Œå®½åˆ†åˆ«å‡å°4ï¼Œè€Œæ± åŒ–å±‚åˆ™å°†é«˜å’Œå®½å‡åŠï¼Œä½†é€šé“æ•°åˆ™ä»1å¢åŠ åˆ°16ã€‚å…¨è¿æ¥å±‚åˆ™é€å±‚å‡å°‘è¾“å‡ºä¸ªæ•°ï¼Œç›´åˆ°å˜æˆå›¾åƒçš„ç±»åˆ«æ•°10ã€‚
![Image Name](https://cdn.kesci.com/upload/image/q5ndxi6jl5.png?imageView2/0/w/640/h/640)



å·ç§¯ç¥ç»ç½‘ç»œå°±æ˜¯å«å·ç§¯å±‚çš„ç½‘ç»œã€‚
LeNetäº¤æ›¿ä½¿ç”¨å·ç§¯å±‚å’Œæœ€å¤§æ± åŒ–å±‚åæ¥å…¨è¿æ¥å±‚æ¥è¿›è¡Œå›¾åƒåˆ†ç±»ã€‚

## æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼ˆAlexNetï¼‰

LeNet:  åœ¨å¤§çš„çœŸå®æ•°æ®é›†ä¸Šçš„è¡¨ç°å¹¶ä¸å°½å¦‚â¼ˆæ„ã€‚     
1.ç¥ç»ç½‘ç»œè®¡ç®—å¤æ‚ã€‚  
2.è¿˜æ²¡æœ‰â¼¤é‡æ·±â¼Šç ”ç©¶å‚æ•°åˆå§‹åŒ–å’Œâ¾®å‡¸ä¼˜åŒ–ç®—æ³•ç­‰è¯¸å¤šé¢†åŸŸã€‚  
  
æœºå™¨å­¦ä¹ çš„ç‰¹å¾æå–:æ‰‹å·¥å®šä¹‰çš„ç‰¹å¾æå–å‡½æ•°  
ç¥ç»ç½‘ç»œçš„ç‰¹å¾æå–ï¼šé€šè¿‡å­¦ä¹ å¾—åˆ°æ•°æ®çš„å¤šçº§è¡¨å¾ï¼Œå¹¶é€çº§è¡¨â½°è¶Šæ¥è¶ŠæŠ½è±¡çš„æ¦‚å¿µæˆ–æ¨¡å¼ã€‚  
  
ç¥ç»ç½‘ç»œå‘å±•çš„é™åˆ¶:æ•°æ®ã€ç¡¬ä»¶

### AlexNet
é¦–æ¬¡è¯æ˜äº†å­¦ä¹ åˆ°çš„ç‰¹å¾å¯ä»¥è¶…è¶Šâ¼¿â¼¯è®¾è®¡çš„ç‰¹å¾ï¼Œä»è€Œâ¼€ä¸¾æ‰“ç ´è®¡ç®—æœºè§†è§‰ç ”ç©¶çš„å‰çŠ¶ã€‚
**ç‰¹å¾ï¼š**
1. 8å±‚å˜æ¢ï¼Œå…¶ä¸­æœ‰5å±‚å·ç§¯å’Œ2å±‚å…¨è¿æ¥éšè—å±‚ï¼Œä»¥åŠ1ä¸ªå…¨è¿æ¥è¾“å‡ºå±‚ã€‚
2. å°†sigmoidæ¿€æ´»å‡½æ•°æ”¹æˆäº†æ›´åŠ ç®€å•çš„ReLUæ¿€æ´»å‡½æ•°ã€‚
3. ç”¨Dropoutæ¥æ§åˆ¶å…¨è¿æ¥å±‚çš„æ¨¡å‹å¤æ‚åº¦ã€‚
4. å¼•å…¥æ•°æ®å¢å¼ºï¼Œå¦‚ç¿»è½¬ã€è£å‰ªå’Œé¢œè‰²å˜åŒ–ï¼Œä»è€Œè¿›ä¸€æ­¥æ‰©å¤§æ•°æ®é›†æ¥ç¼“è§£è¿‡æ‹Ÿåˆã€‚

![Image Name](https://cdn.kesci.com/upload/image/q5kv4gpx88.png?imageView2/0/w/640/h/640)

```
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class AlexNet(nn.Module):
    def __init__(self):
        super(AlexNet, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(1, 96, 11, 4), # in_channels, out_channels, kernel_size, stride, padding
            nn.ReLU(),
            nn.MaxPool2d(3, 2), # kernel_size, stride
            # å‡å°å·ç§¯çª—å£ï¼Œä½¿ç”¨å¡«å……ä¸º2æ¥ä½¿å¾—è¾“å…¥ä¸è¾“å‡ºçš„é«˜å’Œå®½ä¸€è‡´ï¼Œä¸”å¢å¤§è¾“å‡ºé€šé“æ•°
            nn.Conv2d(96, 256, 5, 1, 2),
            nn.ReLU(),
            nn.MaxPool2d(3, 2),
            # è¿ç»­3ä¸ªå·ç§¯å±‚ï¼Œä¸”ä½¿ç”¨æ›´å°çš„å·ç§¯çª—å£ã€‚é™¤äº†æœ€åçš„å·ç§¯å±‚å¤–ï¼Œè¿›ä¸€æ­¥å¢å¤§äº†è¾“å‡ºé€šé“æ•°ã€‚
            # å‰ä¸¤ä¸ªå·ç§¯å±‚åä¸ä½¿ç”¨æ± åŒ–å±‚æ¥å‡å°è¾“å…¥çš„é«˜å’Œå®½
            nn.Conv2d(256, 384, 3, 1, 1),
            nn.ReLU(),
            nn.Conv2d(384, 384, 3, 1, 1),
            nn.ReLU(),
            nn.Conv2d(384, 256, 3, 1, 1),
            nn.ReLU(),
            nn.MaxPool2d(3, 2)
        )
         # è¿™é‡Œå…¨è¿æ¥å±‚çš„è¾“å‡ºä¸ªæ•°æ¯”LeNetä¸­çš„å¤§æ•°å€ã€‚ä½¿ç”¨ä¸¢å¼ƒå±‚æ¥ç¼“è§£è¿‡æ‹Ÿåˆ
        self.fc = nn.Sequential(
            nn.Linear(256*5*5, 4096),
            nn.ReLU(),
            nn.Dropout(0.5),
            #ç”±äºä½¿ç”¨CPUé•œåƒï¼Œç²¾ç®€ç½‘ç»œï¼Œè‹¥ä¸ºGPUé•œåƒå¯æ·»åŠ è¯¥å±‚
            #nn.Linear(4096, 4096),
            #nn.ReLU(),
            #nn.Dropout(0.5),

            # è¾“å‡ºå±‚ã€‚ç”±äºè¿™é‡Œä½¿ç”¨Fashion-MNISTï¼Œæ‰€ä»¥ç”¨ç±»åˆ«æ•°ä¸º10ï¼Œè€Œéè®ºæ–‡ä¸­çš„1000
            nn.Linear(4096, 10),
        )

    def forward(self, img):

        feature = self.conv(img)
        output = self.fc(feature.view(img.shape[0], -1))
        return output
```

### VGGä½¿ç”¨é‡å¤å…ƒç´ çš„ç½‘ç»œ
VGGï¼šé€šè¿‡é‡å¤ä½¿â½¤ç®€å•çš„åŸºç¡€å—æ¥æ„å»ºæ·±åº¦æ¨¡å‹ã€‚  
Block:æ•°ä¸ªç›¸åŒçš„å¡«å……ä¸º1ã€çª—å£å½¢çŠ¶ä¸º$3\times 3$çš„å·ç§¯å±‚,æ¥ä¸Šä¸€ä¸ªæ­¥å¹…ä¸º2ã€çª—å£å½¢çŠ¶ä¸º$2\times 2$çš„æœ€å¤§æ± åŒ–å±‚ã€‚  
å·ç§¯å±‚ä¿æŒè¾“å…¥çš„é«˜å’Œå®½ä¸å˜ï¼Œè€Œæ± åŒ–å±‚åˆ™å¯¹å…¶å‡åŠã€‚

![Image Name](https://cdn.kesci.com/upload/image/q5l6vut7h1.png?imageView2/0/w/640/h/640)

```
def vgg_block(num_convs, in_channels, out_channels): #å·ç§¯å±‚ä¸ªæ•°ï¼Œè¾“å…¥é€šé“æ•°ï¼Œè¾“å‡ºé€šé“æ•°
    blk = []
    for i in range(num_convs):
        if i == 0:
            blk.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))
        else:
            blk.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))
        blk.append(nn.ReLU())
    blk.append(nn.MaxPool2d(kernel_size=2, stride=2)) # è¿™é‡Œä¼šä½¿å®½é«˜å‡åŠ
    return nn.Sequential(*blk)

def vgg(conv_arch, fc_features, fc_hidden_units=4096):
    net = nn.Sequential()
    # å·ç§¯å±‚éƒ¨åˆ†
    for i, (num_convs, in_channels, out_channels) in enumerate(conv_arch):
        # æ¯ç»è¿‡ä¸€ä¸ªvgg_blockéƒ½ä¼šä½¿å®½é«˜å‡åŠ
        net.add_module("vgg_block_" + str(i+1), vgg_block(num_convs, in_channels, out_channels))
    # å…¨è¿æ¥å±‚éƒ¨åˆ†
    net.add_module("fc", nn.Sequential(d2l.FlattenLayer(),
                                 nn.Linear(fc_features, fc_hidden_units),
                                 nn.ReLU(),
                                 nn.Dropout(0.5),
                                 nn.Linear(fc_hidden_units, fc_hidden_units),
                                 nn.ReLU(),
                                 nn.Dropout(0.5),
                                 nn.Linear(fc_hidden_units, 10)
                                ))
    return net
		
```
###  â½¹ç»œä¸­çš„â½¹ç»œï¼ˆNiNï¼‰ 
LeNetã€AlexNetå’ŒVGGï¼šå…ˆä»¥ç”±å·ç§¯å±‚æ„æˆçš„æ¨¡å—å……åˆ†æŠ½å– ç©ºé—´ç‰¹å¾ï¼Œå†ä»¥ç”±å…¨è¿æ¥å±‚æ„æˆçš„æ¨¡å—æ¥è¾“å‡ºåˆ†ç±»ç»“æœã€‚  
NiNï¼šä¸²è”å¤šä¸ªç”±å·ç§¯å±‚å’Œâ€œå…¨è¿æ¥â€å±‚æ„æˆçš„å°â½¹ç»œæ¥æ„å»ºâ¼€ä¸ªæ·±å±‚â½¹ç»œã€‚  
â½¤äº†è¾“å‡ºé€šé“æ•°ç­‰äºæ ‡ç­¾ç±»åˆ«æ•°çš„NiNå—ï¼Œç„¶åä½¿â½¤å…¨å±€å¹³å‡æ± åŒ–å±‚å¯¹æ¯ä¸ªé€šé“ä¸­æ‰€æœ‰å…ƒç´ æ±‚å¹³å‡å¹¶ç›´æ¥â½¤äºåˆ†ç±»ã€‚  

![Image Name](https://cdn.kesci.com/upload/image/q5l6u1p5vy.png?imageView2/0/w/960/h/960)

1Ã—1å·ç§¯æ ¸ä½œç”¨   
1.æ”¾ç¼©é€šé“æ•°ï¼šé€šè¿‡æ§åˆ¶å·ç§¯æ ¸çš„æ•°é‡è¾¾åˆ°é€šé“æ•°çš„æ”¾ç¼©ã€‚  
2.å¢åŠ éçº¿æ€§ã€‚1Ã—1å·ç§¯æ ¸çš„å·ç§¯è¿‡ç¨‹ç›¸å½“äºå…¨è¿æ¥å±‚çš„è®¡ç®—è¿‡ç¨‹ï¼Œå¹¶ä¸”è¿˜åŠ å…¥äº†éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œä»è€Œå¯ä»¥å¢åŠ ç½‘ç»œçš„éçº¿æ€§ã€‚  
3.è®¡ç®—å‚æ•°å°‘

NiNé‡å¤ä½¿â½¤ç”±å·ç§¯å±‚å’Œä»£æ›¿å…¨è¿æ¥å±‚çš„1Ã—1å·ç§¯å±‚æ„æˆçš„NiNå—æ¥æ„å»ºæ·±å±‚â½¹ç»œã€‚  
NiNå»é™¤äº†å®¹æ˜“é€ æˆè¿‡æ‹Ÿåˆçš„å…¨è¿æ¥è¾“å‡ºå±‚ï¼Œè€Œæ˜¯å°†å…¶æ›¿æ¢æˆè¾“å‡ºé€šé“æ•°ç­‰äºæ ‡ç­¾ç±»åˆ«æ•° çš„NiNå—å’Œå…¨å±€å¹³å‡æ± åŒ–å±‚ã€‚   
NiNçš„ä»¥ä¸Šè®¾è®¡æ€æƒ³å½±å“äº†åâ¾¯â¼€ç³»åˆ—å·ç§¯ç¥ç»â½¹ç»œçš„è®¾è®¡ã€‚  


```
def nin_block(in_channels, out_channels, kernel_size, stride, padding):
    blk = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),
                        nn.ReLU(),
                        nn.Conv2d(out_channels, out_channels, kernel_size=1),
                        nn.ReLU(),
                        nn.Conv2d(out_channels, out_channels, kernel_size=1),
                        nn.ReLU())
    return blk
class GlobalAvgPool2d(nn.Module):
    # å…¨å±€å¹³å‡æ± åŒ–å±‚å¯é€šè¿‡å°†æ± åŒ–çª—å£å½¢çŠ¶è®¾ç½®æˆè¾“å…¥çš„é«˜å’Œå®½å®ç°
    def __init__(self):
        super(GlobalAvgPool2d, self).__init__()
    def forward(self, x):
        return F.avg_pool2d(x, kernel_size=x.size()[2:])

net = nn.Sequential(
    nin_block(1, 96, kernel_size=11, stride=4, padding=0),
    nn.MaxPool2d(kernel_size=3, stride=2),
    nin_block(96, 256, kernel_size=5, stride=1, padding=2),
    nn.MaxPool2d(kernel_size=3, stride=2),
    nin_block(256, 384, kernel_size=3, stride=1, padding=1),
    nn.MaxPool2d(kernel_size=3, stride=2), 
    nn.Dropout(0.5),
    # æ ‡ç­¾ç±»åˆ«æ•°æ˜¯10
    nin_block(384, 10, kernel_size=3, stride=1, padding=1),
    GlobalAvgPool2d(), 
    # å°†å››ç»´çš„è¾“å‡ºè½¬æˆäºŒç»´çš„è¾“å‡ºï¼Œå…¶å½¢çŠ¶ä¸º(æ‰¹é‡å¤§å°, 10)
    d2l.FlattenLayer())
X = torch.rand(1, 1, 224, 224)
for name, blk in net.named_children(): 
    X = blk(X)
    print(name, 'output shape: ', X.shape)
'''
0 output shape:  torch.Size([1, 96, 54, 54])
1 output shape:  torch.Size([1, 96, 26, 26])
2 output shape:  torch.Size([1, 256, 26, 26])
3 output shape:  torch.Size([1, 256, 12, 12])
4 output shape:  torch.Size([1, 384, 12, 12])
5 output shape:  torch.Size([1, 384, 5, 5])
6 output shape:  torch.Size([1, 384, 5, 5])
7 output shape:  torch.Size([1, 10, 5, 5])
8 output shape:  torch.Size([1, 10, 1, 1])
9 output shape:  torch.Size([1, 10])
'''
```


### GoogLeNet :Networks with Parallel Concatenations
1. ç”±InceptionåŸºç¡€å—ç»„æˆã€‚  
2. Inceptionå—ç›¸å½“äºâ¼€ä¸ªæœ‰4æ¡çº¿è·¯çš„â¼¦â½¹ç»œã€‚å®ƒé€šè¿‡ä¸åŒçª—å£å½¢çŠ¶çš„å·ç§¯å±‚å’Œæœ€â¼¤æ± åŒ–å±‚æ¥å¹¶â¾æŠ½å–ä¿¡æ¯ï¼Œå¹¶ä½¿â½¤1Ã—1å·ç§¯å±‚å‡å°‘é€šé“æ•°ä»è€Œé™ä½æ¨¡å‹å¤æ‚åº¦ã€‚   
3. å¯ä»¥â¾ƒå®šä¹‰çš„è¶…å‚æ•°æ˜¯æ¯ä¸ªå±‚çš„è¾“å‡ºé€šé“æ•°ï¼Œæˆ‘ä»¬ä»¥æ­¤æ¥æ§åˆ¶æ¨¡å‹å¤æ‚åº¦ã€‚ 



![Image Name](https://cdn.kesci.com/upload/image/q5weakogtb.png?imageView2/0/w/640/h/640)



å®Œæ•´æ¨¡å‹ç»“æ„  

![Image Name](https://cdn.kesci.com/upload/image/q5l6x0fyyn.png?imageView2/0/w/640/h/640)


```
class Inception(nn.Module):
    # c1 - c4ä¸ºæ¯æ¡çº¿è·¯é‡Œçš„å±‚çš„è¾“å‡ºé€šé“æ•°
    def __init__(self, in_c, c1, c2, c3, c4):
        super(Inception, self).__init__()
        # çº¿è·¯1ï¼Œå•1 x 1å·ç§¯å±‚
        self.p1_1 = nn.Conv2d(in_c, c1, kernel_size=1)
        # çº¿è·¯2ï¼Œ1 x 1å·ç§¯å±‚åæ¥3 x 3å·ç§¯å±‚
        self.p2_1 = nn.Conv2d(in_c, c2[0], kernel_size=1)
        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)
        # çº¿è·¯3ï¼Œ1 x 1å·ç§¯å±‚åæ¥5 x 5å·ç§¯å±‚
        self.p3_1 = nn.Conv2d(in_c, c3[0], kernel_size=1)
        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)
        # çº¿è·¯4ï¼Œ3 x 3æœ€å¤§æ± åŒ–å±‚åæ¥1 x 1å·ç§¯å±‚
        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)
        self.p4_2 = nn.Conv2d(in_c, c4, kernel_size=1)

    def forward(self, x):
        p1 = F.relu(self.p1_1(x))
        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))
        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))
        p4 = F.relu(self.p4_2(self.p4_1(x)))
        return torch.cat((p1, p2, p3, p4), dim=1)  # åœ¨é€šé“ç»´ä¸Šè¿ç»“è¾“å‡º
```


```python
å‚è€ƒï¼š
https://zhuanlan.zhihu.com/p/32481747
https://zhuanlan.zhihu.com/p/32085405
```


```python

```
